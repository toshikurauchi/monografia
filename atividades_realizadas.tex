\section{Atividades realizadas}
\label{atividades}
As ideias apresentadas a seguir foram aplicadas no desenvolvimento da engine e da aplicação de visualização de campos tensoriais.

\subsection{Objetos da API gráfica}

Nessa seção serão descritos os mapeamentos utilizados pela engine para os objetos mais comuns definidos pelo OpenGL. Todos os mapeamentos foram projetados de forma que os objetos pudessem ser utilizados fora de um contexto inicializado e, além disso, os o objeto do OpenGL só é instanciado se necessário, o que economiza recursos da placa gráfica.

\subsubsection {Buffer}

Um \texttt{Buffer} é uma região de memória controlado pelo driver gráfico. O conceito de \texttt{Buffer} foi criado para resolver o gargalo da comunicação entre Memória Principal e Memória de Vídeo.

No OpenGL, buffers são criados através da função glGenBuffers. Depois de criado, o buffer deve ser associado ao contexto do OpenGL, para isso utiliza-se o comando glBindBuffer, esse comando, além de informar ao OpenGL que o buffer deve ser associado ao contexto, faz com que os dados presentes no buffer sejam interpretados de forma diferente. Por exemplo, para informar que o buffer será utilizado para fornecer vértices ao pipeline, utiliza-se:

\begin{verbatim}
glBindBuffer(GL_ARRAY_BUFFER);
\end{verbatim}

Com o buffer associado ao contexto, é necessário inicializar os dados do buffer. Essa inicialização é feita pelo comando \texttt{glBufferData}. Após esses procedimentos, o buffer está pronto para ser utilizado.

% Colocar \texttt nos GL_WRITE_ONLY e outras constantes
Uma das características mais importantes do \texttt{buffer} é a possibilidade de mapeá-lo em uma região de memória que pode ser acessada pela aplicação. Esse mapeamento é importante, pois ele permite que a aplicação informe ao OpenGL que política de acesso a aplicação adotará para ler ou escrever na memória mapeada. Por exemplo, se o buffer for mapeado utilizando-se GL\_WRITE\_ONLY, o driver gráfico não precisa copiar os dados da memória do driver para a memória principal, o que diminui a troca de dados entre a memória de vídeo e a memória principal.

As políticas de acesso definidas pelo OpenGL são: 
\begin{itemize}
\item GL\_READ\_ONLY: quando a aplicação planeja apenas ler a região de memória
\item GL\_WRITE\_ONLY: quando a região de memória for utilizada apenas para escrita
\item GL\_READ\_WRITE: quando a memória mapeada for utilizada para leitura e escrita
\end{itemize}

O mapeamento de um vertex buffer que será utilizado somente para escrita pode ser feito através do seguinte código:

\begin{verbatim}
glBindBuffer(GL_ARRAY_BUFFER, bufferID);
void * mappedBuffer = glMapBuffer(GL_ARRAY_BUFFER, GL_WRITE_ONLY);
\end{verbatim}

Após a utilização da região mapeada, é importante cancelar o mapeamento feito. Esse cancelamento é feito através da função \texttt{glUnmapBuffer};

% Precisa desses texttt?
Na \texttt{Pandora's Box}, \texttt{buffer}s são implementações da interface \texttt{Buffer}. O buffer padrão do OpenGL é implementado pela classe GLBuffer:
\begin{verbatim}
// GLBuffer.h
#ifndef PBGE_GRAPHIC_API_GL_BUFFER
#define PBGE_GRAPHIC_API_GL_BUFFER

#include <GL/glew.h>
#include "pbge/gfx/Buffer.h"

namespace pbge {
    class GLGraphic;
    class GLObjectsFactory;

    // TODO: make changes to the buffer interface
    class GLBuffer : public Buffer {
    public:
        friend GLObjectsFactory;

        // returns the data buffer
        void * map(Buffer::AccessPattern access);

        void unmap();

        void unbind();

        void bindOn(Buffer::Target _target);

        GLuint getID() {
            return glID;
        }
    private:
        // retirei o target
        GLBuffer(size_t _size, Buffer::UsageHint _usage, GLGraphic * _gl);
        
        void destroy();

        void initialize();
        
        GLGraphic * gl;

        GLenum usage;

        GLenum target;

        void * data;

        GLuint glID;

        size_t size;
    };
}
#endif
\end{verbatim}
\begin{verbatim}
// GLBuffer.cpp
#include <GL/glew.h>

#include "OpenGLAPI/gfx/GLGraphic.h"
#include "OpenGLAPI/gfx/GLBuffer.h"

using namespace pbge;

GLenum translateUsageHint(Buffer::UsageHint usageHint) {
    GLenum usage;
    switch (usageHint) {
        case Buffer::STREAM_COPY: usage = GL_STREAM_COPY; break;
        case Buffer::STREAM_DRAW: usage = GL_STREAM_DRAW; break;
        case Buffer::STREAM_READ: usage = GL_STREAM_READ; break;

        case Buffer::STATIC_COPY: usage = GL_STATIC_COPY; break;
        case Buffer::STATIC_DRAW: usage = GL_STATIC_DRAW; break;
        case Buffer::STATIC_READ: usage = GL_STATIC_READ; break;

        case Buffer::DYNAMIC_COPY: usage = GL_DYNAMIC_COPY; break;
        case Buffer::DYNAMIC_DRAW: usage = GL_DYNAMIC_DRAW; break;
        case Buffer::DYNAMIC_READ: usage = GL_DYNAMIC_READ; break;
        default: throw 1;
    }
    return usage;
}

GLBuffer::GLBuffer(size_t _size, Buffer::UsageHint _usage, GLGraphic * ogl):size(_size), target(0), glID(0), gl(ogl) {
    this->usage = translateUsageHint(_usage);
    this->data = malloc(size);
    if (this->data == NULL) {
        // error
    }
} 

void * GLBuffer::map(AccessPattern accessPattern) {
    unsigned access = 0;
    if(data != NULL) {
        return data;
    }
    switch(accessPattern) {
        case READ_ONLY: access = GL_READ_ONLY; break;
        case WRITE_ONLY: access = GL_WRITE_ONLY; break;
        case READ_WRITE: access = GL_READ_WRITE; break;
        // TODO: log warn
        default: throw 1;
    }
    glBindBuffer(target, glID);
    return glMapBuffer(target, access);
}

void GLBuffer::unmap() {
    if(data == NULL)
        glUnmapBuffer(target);
}

void GLBuffer::bindOn(Target _target) {
    GLenum bindPoint = 0;
    switch(_target) {
        case Buffer::VertexBuffer: bindPoint = GL_ARRAY_BUFFER; break;
        case Buffer::IndexBuffer: bindPoint = GL_ELEMENT_ARRAY_BUFFER; break;
        case Buffer::PixelReadBackBuffer: bindPoint = GL_PIXEL_PACK_BUFFER; break;
        case Buffer::PixelSendBuffer: bindPoint = GL_PIXEL_UNPACK_BUFFER; break;
        case Buffer::BufferTextureStorage: bindPoint = gl->getExtensions().getBufferTextureInfo().bufferBinding;
    }
    if(bindPoint == 0) {
        throw 1;
    }
    // the default target will be the target of the first bind
    if (this->target == 0) {
        this->target = bindPoint;
    }
    if (this->glID == 0) {
        this->initialize();
    }
    glBindBuffer(bindPoint, glID);
}

void GLBuffer::unbind() {
    glBindBuffer(target, 0);
}

void GLBuffer::initialize() {
    glGenBuffers(1, &glID);
    glBindBuffer(target, glID);
    if (data != NULL) {
        glBufferData(target, size, data, usage);
        delete data;
        data = NULL;
    } else { // maybe allocation failed?
        glBufferData(target, size, NULL, usage);
    }
}

void GLBuffer::destroy() {
    if (glID != 0) {
        glDeleteBuffers(1, &glID);
    }
    if (this->data != NULL) {
        delete data;
    }
}
\end{verbatim}

Exemplo de uso de um \texttt{buffer} da \texttt{Pandora's Box}:
\begin{verbatim}
GraphicAPI *gfx = ...;
// cria um buffer de tamanho size e com política de uso usage
// As políticas de uso permitidas são:
// STREAM_DRAW, STREAM_READ, STREAM_COPY, STATIC_DRAW, STATIC_READ, 
// STATIC_COPY, DYNAMIC_DRAW, DYNAMIC_READ e DYNAMIC_COPY
Buffer *buffer = gfx->getFactory()->createBuffer(size, usage);
pbge::Buffer::STATIC_DRAW);
void * mapped = buffer->map(pbge::Buffer::WRITE_ONLY);
// operar na região mapeada
buffer->unmap();
\end{verbatim}

\subsubsection {Shaders}

Como explicado anteriormente, o OpenGL opera nas primitivas gráficas através de um pipeline, que tem cinco estágios principais: transformação de vértices, tesselagem, criação de novas primitivas, rasterização e operações por fragmento. Com exceção da rasterização, todos os estágios podem ser customizados pelo uso de shaders.

No OpenGL, shaders são criados através da função \texttt{glCreateShader}, que retorna um handler para o shader criado, com o handler devolvido, é possível especificar o código fonte que será utilizado utilizando-se a função \texttt{glShaderSource}. Após associar um código fonte ao shader, ele pode ser compilado por \texttt{glCompileShader}. Para utilizar o shader criado, ele deve ser associado a um programa.

Programas, no OpenGL, são criados por \texttt{glCreateProgram}, que retorna o handler para o programa criado. Depois de criado, o programa precisa ser associado a shaders, a associação é feita pela função \texttt{glAttachShader}. Quando todos os shaders necessários estiverem associados ao programa, ele pode ser preparado para execução através do comando \texttt{glLinkProgram}. Para sobrescrever o pipeline com o programa criado utiliza-se a função \texttt{glUseProgram}.

Na Pandora's Box, shaders são implementações da classe \texttt{Shader} e podem ser criados através da \texttt{GraphicObjectsFactory}. Para que possam ser utilizados para sobrescrever o pipeline, os shaders devem ser associados a um GPUProgram. A criação de um GPUProgram que sobrescreve tanto a transformação de vértices quanto o processamento de pixels é exemplificada abaixo:

\begin{verbatim}
GraphicAPI * gfx = ...;
Shader * vertexShader = gfx->createShaderFromString(vertexShaderSource, pbge::Shader::VERTEX_SHADER);
Shader * fragmentShader = gfx->createShaderFromString(fragmentShaderSource, pbge::Shader::FRAGMENT_SHADER);
std::vector<Shader*> vertexShaders;
std::vector<Shader*> fragmentShaders;
vertexShaders.push_back(vertexShader);
fragmentShaders.push_back(fragmentShader);
GPUProgram * program = gfx->getFactory()->createProgram(vertexShaders, fragmentShaders);
\end{verbatim}

O código acima pode ainda ser simplificado para:

\begin{verbatim}
GraphicAPI * gfx = ...;
GPUProgram * program = createProgramFromString(vertexShaderSource, fragmentShaderSource);
\end{verbatim}

O \texttt{GPUProgram} criado é utilizado para sobrescrever o pipeline através do código:

\begin{verbatim}
GraphicAPI * gfx = ...;
GPUProgram * program = ...;
gfx->getState()->useProgram(program);
\end{verbatim}


\subsubsection{Texturas}

Texturas no OpenGL são simplesmente tabelas de valores. Em aplicações mais antigas, as texturas eram utilizadas quase exclusivamente para o armazenamento de imagens que seriam mapeadas nos objetos da cena ou máscaras em técnicas avançadas, porém com o surgimento da computação genérica em GPU (GPGPU), as texturas passaram a ser utilizadas de forma análoga aos vetores e matrizes de linguagens como C++.

No OpenGL as texturas são criadas com o comando \texttt{glGenTextures}, que gera um handler para o objeto vazio criado, em seguida para é necessário associar o objeto criado ao contexto do OpenGL, o que é feito pelo comando \texttt{glBindBuffer}. Com a textura vazia associada ao contexto, é possível inicializar seus dados através de um comando da família \texttt{glTexImage}.

Na Pandora's Box, texturas são implementações da interface \texttt{Texture}. Como a inicialização e uso de uma textura dependem da API gráfica utilizada, sua construção fica a cargo da \texttt{GraphicObjectsFactory}. A inicialização de uma textura 2D é demonstrada no código abaixo:

\begin{verbatim}
GraphicAPI * gfx = ...;
// image é uma interface que representa uma fonte de dados para uma textura 2D.
Image * image = ...;
Texture2D * texture = gfx->getFactory()->create2DTexture();
// especifica a imagem e como os dados devem ser representados na GPU
texture->setImageData(image, pbge::Texture::RGBA);
\end{verbatim}

Com o aumento da quantidade de dados enviados à GPU através de texturas, surge um problema, as texturas padrão das APIs gráficas conseguem indexar apenas um pequeno número de pixels na textura, cerca de 2048 em placas recentes. Para resolver esse problema, o OpenGL introduziu o conceito de texture buffer, uma textura de uma dimensão que utiliza um buffer para armazenar dados, essa nova textura consegue indexar no mínimo 65536 pixels, segundo a especificação do OpenGL 4.2.

A criação de um buffer texture é feita de forma ligeiramente diferente de uma textura convencional. Após a criação do handler, a textura deve ser associada ao contexto através da chamada \texttt{glBindTexture(GL\_TEXTURE\_BUFFER, handler)}, após a associação, o buffer que será utilizado pela textura é definido pelo comando \texttt{glTexBuffer}.

Na engine, os texture buffer são texturas que implementam a interface \texttt{TextureBuffer} e que também devem ser construídas através da \texttt{GraphicObjectsFactory}. Um exemplo de criação de texture buffer é dado no código abaixo:

\begin{verbatim}
GraphicAPI *gfx = ...
TextureBuffer * texture = gfx->getFactory()->createTextureBuffer(size);
// a textura será representada como um conjunto de 4 floats
// por texel (elemento da textura)
texture->setInternalFormat(pbge::Texture::FLOAT, pbge::Texture::RGBA);
// recupera o buffer associado à textura
Buffer *buffer = texture->getBuffer();
float * data = (float*) buffer->map(pbge::Buffer::WRITE_ONLY);
// inicialização dos dados do buffer
buffer->unmap();
\end{verbatim}

Após a criação das texturas, elas são enviadas ao shader através dos \texttt{UniformSet}, como demonstrado abaixo no caso de uma textura 2D:
\begin{verbatim}
GraphicAPI *gfx = ...;
Texture2D * texture = ...;
UniformSet uniforms;
// associa a textura texture à variável do shader do tipo sampler2D
// chamada shader_texture
uniforms->getSampler2D("shader_texture")->setValue(texture);
gfx->pushUniforms(&uniforms);
\end{verbatim}




\subsubsection{VertexBuffer}
No início da computação gráfica, os vértices eram especificados um a um através de chamadas à API gráfica, por exemplo, a especificação de um triângulo no OpenGL era feita da seguinte maneira:

\begin{verbatim}
glBegin(GL_TRIANGLES);
glVertex3f(0.0f, 0.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glVertex3f(0.0f, 1.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glVertex3f(1.0f, 0.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glEnd();
\end{verbatim}

É possível observar que o número de chamadas de função cresce linearmente com a quantidade de vértices do modelo, além disso cada um dos atributos do vértice (posição, cor, normal, entre outros) era especificado através de uma chamada de função diferente.

\begin{wrapfigure}{r}{0.6\textwidth}
\vspace{-20pt}
\begin{center}
\includegraphics[width=0.6\textwidth]{vertexbuffer}
\end{center}
\vspace{-20pt}
\caption{O vertex buffer\label{vertexbuffer}}
\vspace{-10pt}
\end{wrapfigure}

Com o aumento da complexidade dos modelos, foi necessário reinventar a API existente, com isso foi criado o conceito de \texttt{vertex array}, que é simplesmente um vetor de valores de tipos variados em que cada atributo é especificado através de seu tipo primitivo (double, float, int, short, byte) número de componentes, significado (posição, vetor normal, coordenada de textura, \ldots) e a distância em bytes para o próximo valor desse atributo no vetor. Essa estrutura é exemplificada na figura ao lado.

Como a especificação desse modelo de dados era flexível e permitia enviar uma grande quantidade de dados para a \texttt{GPU} em um número constante de chamadas de função, ele foi rapidamente adotado pelos programadores.

Mas esse modelo não solucionava o problema de tráfego de dados entre a memória principal (RAM) e a memória de vídeo (VRAM). A solução foi colocar o \texttt{vertex array} dentro de um buffer gerenciado pela implementação da API gráfica, assim, a implementação poderia colocar dados muito utilizados dentro de regiões de fácil acesso, como a VRAM. Essa solução ficou conhecida como \texttt{Vertex Buffer}

Na Pandora's Box, \texttt{Vertex Buffers} são especificados através da classe VertexBuffer, sua estrutura interna é semelhante à apresentada na Figura~\ref{vertexbuffer}.
Cada vértice é especificado através da classe VertexAttrib que guarda informações sobre o primeiro índice do atributo dentro o buffer, seu significado, número de componentes e qual a distância entre valores consecutivos do atributo.

A forma recomendada de se criar um \texttt{VertexBuffer} é através do \texttt{VertexBufferBuilder}. % falar mais sobre o vertexbufferbuilder

% como construir com o builder: texto explicando?
\begin{verbatim}
pbge::VertexBuffer * criaVertexBuffer(pbge::GraphicAPI * gfx) {
    int nVertices = ...; // Inicializa com o número de vértices desejado
    pbge::VertexBufferBuilder builder(nVertices);
    pbge::VertexAttribBuilder vertex = builder.addAttrib(4, VertexAttrib::VERTEX);
    pbge::VertexAttribBuilder color = builder.addAttrib(4, VertexAttrib::COLOR);
    for(int i = 0; i < nVertices; i++) {
        float x, y, z, w; // Inicializados com os valores desejados
        float r, g, b, a; // Inicializados com os valores desejados
        builder.on(vertex).pushValue(x, y, z, w);
        builder.on(color).pushValue(r, g, b, a);
    }
    return builder.done(Buffer::STATIC_DRAW, gfx);
}
\end{verbatim}

% Esse código é suficiente?
% Talvez valha a pena comentar sobre o VBOModel...




\subsubsection {FrameBufferObject}

O framebuffer é o destino dos pixels gerados através do pipeline. Existem dois tipos de framebuffer:

\begin{itemize}
\item O framebuffer do sistema de janelas: é o framebuffer que deve ser utilizado quando os pixels devem ser enviados para a janela da aplicação.
\item framebuffer virtual: é o framebuffer utilizado para renderização direta em texturas.
\end{itemize}

Os framebuffer objects encapsulam o segundo tipo. No OpenGL, framebuffer objects são criados pela função \texttt{glGenFramebuffersEXT}, que gera um handler que representa o objeto criado. Para associar uma textura ao framebuffer object criado utiliza-se a função \texttt{glFramebufferTexture2DEXT} e, por fim, para adicionar um buffer de profundidade, para permitir testes de profundidade, usa-se \texttt{glFramebufferTexture2DEXT}.

Para utilizar o framebuffer object criado, é necessário associá-lo ao contexto do OpenGL com o comando \texttt{glBindFramebufferEXT} e em seguida redirecionar os pixels gerados pelo pipeline através do comando \texttt{glDrawBuffers}.

Na engine desenvolvida, framebuffer objects são implementações da interface \texttt{FramebufferObject} e devem ser instanciados através da \texttt{GraphicObjectsFactory}. A criação e uso de framebuffer objects dentro da Pandora's Box é exemplificado abaixo:

\begin{verbatim}
GraphicAPI * gfx = ...;
Texture2D * color = ...;
Texture2D * depth = ...;
FramebufferObject * fbo = gfx->getFactory()->createFramebuffer(width, height);
// associa os valores escritos pelo shader na variável color_out à textura color
fbo->addRenderable(color, "color_out");
// usa depth como buffer de profundidade
fbo->setDepthRenderable(depth);
// associa o framebuffer object ao contexto
gfx->bindFramebufferObject(fbo);
\end{verbatim}



\subsection{Grafo de cena}
%TODO: Tudo bem falar que é uma árvore? Geral sobre o que é o grafo de cena, como é percorrido, etc.
A Pandora's Box utiliza um grafo enraizado, direcionado, sem circuitos, conhecido como grafo de cena, para representar a estrutura de uma cena. As mudanças realizadas por cada nó são aplicadas somente a si mesmo e aos seus filhos.

Para realizar a renderização da cena são realizadas buscas em profundidade no grafo até que todas as informações necessárias tenham sido obtidas. Esse processo será melhor explicado em ~\ref{visitors}.

\subsubsection{Tipos de nós}

%TODO: Verificar se falta informação
A engine define quatro tipos de nós padrão: \texttt{TransformationNode}, \texttt{CameraNode}, \texttt{ModelInstance} e \texttt{ModelCollection} (transformação, câmera, modelo e coleção de modelos respectivamente). 

Para implementar nós com comportamentos customizados basta criar uma nova classe filha de Node ou de algum de seus descendentes. A classe Node define essencialmente os métodos de atualização (\texttt{updatePass} e \texttt{postUpdatePass}) e renderização (\texttt{renderPass} e \texttt{postRenderPass}) que devem ser implementados por seus filhos, além de outros métodos específicos da estrutura do grafo.

Os métodos de atualização são chamados para preparar a cena para a renderização (inicialização de variáveis ou atualização de valores, por exemplo).

\begin{itemize}
% Isso esta suficiente?
\item \textbf{TransformationNode}: Esse nó guarda uma matriz de transformação $T$. No \texttt{updatePass} e \texttt{renderPass} a matriz corrente $M$ é armazenada e multiplicada por $T$ e o resultado é utilizado como a nova matriz de transformação corrente. Então no \texttt{postUpdatePass} e \texttt{postRenderPass} $M$ é reatribuída à matriz corrente.
\item \textbf{CameraNode}: O nó possui uma instância da classe Camera que é responsável por receber os parâmetros de câmera (configurações de posição e campo de visão), calcular a matriz de transformação a partir dessas informações e atualizar o estado do OpenGL para utilizá-la. Todas essas ações são realizadas no \texttt{updatePass}.
\item \textbf{ModelInstance}: O método \texttt{renderPass} é responsável por adicionar os shaders e suas uniformes e então solicitar a renderização do modelo pela API gráfica. O método \texttt{postRenderPass} retira as uniformes adicionadas.
\item \textbf{ModelCollection}: A implementação desse nó é análoga à do \texttt{ModelInstance}, com a diferença de que a quantidade de instâncias a serem renderizadas é recebida no construtor e enviada na solicitação da renderização do modelo pela API gráfica.
\end{itemize}

\subsubsection{Node Visitors}
\label{visitors}

Como foi explicado, o grafo de cena é um grafo enraizado, direcionado e sem circuitos, um \texttt{Node Visitor} é uma classe que dado a raíz do grafo de cena, consegue percorrer os nós do grafo obedecendo as seguintes regras:

\begin{itemize}
\item Todos os caminhos do grafo devem ser percorridos, se possível.
\item O estado do \texttt{visitor} ao visitar um dado nó A, deve depender apenas das modificações feitas por nós dentro do caminho da raíz do grafo até A.
\end{itemize}

O segundo item da lista acima, faz com que o grafo de cena represente uma estrutura hierárquica.

Dentro da engine, existem duas implementações concretas do \texttt{visitor} descrito: UpdaterVisitor e ColorPassVisitor.

O UpdaterVisitor é um \texttt{visitor} encarregado de passar por cada nó do grafo de cena e chamar o método updatePass, visitar todos os nós filhos do nó atual, chamar o método postUpdatePass e por fim atualizar o bounding box do nó atual, como exemplificado no código abaixo:

\begin{verbatim}
void UpdaterVisitor::dfsVisit(Node * node, GraphicAPI * gfx) {
    node->updatePass(this, gfx);
    std::vector<Node*>::iterator child;
    for(child = node->getChildren().begin(); child != node->getChildren().end(); child++)
        dfsVisit(*child, gfx);
    node->postUpdatePass(this, gfx);
    if(node->getBoundingVolume() != NULL) {
        node->getBoundingVolume()->update(getCurrentTransformation());
    }
}
\end{verbatim}

O \texttt{ColorPassVisitor} é uma implementação concreta da classe abstrata \texttt{RenderVisitor} que tem a função de chamar os métodos \texttt{renderPass} e \texttt{postRenderPass} do nó durante a execução dos métodos \texttt{visitAction} e \texttt{postVisitAction}, respectivamente, do \texttt{RenderVisitor}:

\begin{verbatim}
class ColorPassVisitor : public RenderVisitor {
public:
    void visitAction(Node * node, GraphicAPI * gfx) {
        node->renderPass(this, gfx);
    }
    void postVisitAction(Node * node, GraphicAPI * gfx) {
        node->postRenderPass(this, gfx);
    }
};
\end{verbatim}

O \texttt{RenderVisitor} é a classe base de todos os \texttt{visitors} que fazem renderização. Para extendê-la, a classe filha deve implementar dois métodos: \texttt{visitAction} e \texttt{postVisitAction}. Esse é importante, pois implementa o conceito de \texttt{frustum culling}.

\texttt{Frustum Culling} é o processo de renderizar apenas objetos que são visíveis para a câmera atual. Na \texttt{Pandora's Box}, um nó é considerado não visível se ele não colide com o \texttt{frustum} da câmera corrente e ao ser considerado não visível, ele e seus nós filhos não são visitados pelo \texttt{RenderVisitor}. Esse teste de visibilidade é executado dentro do método \texttt{dfsVisit} do \texttt{RenderVisitor}:

\begin{verbatim}
void RenderVisitor::dfsVisit(Node * node, GraphicAPI * gfx) {
    if(node->getBoundingVolume() == NULL || node->getBoundingVolume()->frustumCullingTest(boundingFrustum)) {
        visitAction(node, gfx);
        std::vector<Node*>::iterator child;
        for(child = node->getChildren().begin(); child != node->getChildren().end(); child++)
            dfsVisit(*child, gfx);
        postVisitAction(node, gfx);
    }
}
\end{verbatim}

\begin{center}
\begin{longtable}{cc}
\epsfig{file=frustum1.eps, width=0.5\linewidth,clip=}
\epsfig{file=frustum2.eps, width=0.5\linewidth,clip=}
\end{longtable}
\end{center}

\subsection{Renderizador}

O renderizador da engine gráfica utiliza um algoritmo de 3 fases:

\begin{itemize}
\item Atualização dos nós do grafo de cena
\item Processamento do grafo de cena
\item Pós-Processamento da imagem gerada pela fase de processamento
\end{itemize}

\subsubsection {Fase de atualização}

Nessa fase, um \texttt{UpdaterVisitor} é utilizado para visitar e atualizar todos os nós do grafo de cena. É a única fase não customizável do algoritmo do renderizador.

\subsubsection {Fase de processamento do grafo de cena}

Nessa fase executa-se uma sequência de algoritmos definida pelo usuário da engine, a execução é equivalente ao código:

%verificar se os argumentos estão corretos
\begin{verbatim}
std::vector<SceneProcessor*>::iterator it;
for(it = processors.begin(); it != processors.end(); it++){
   if(it->isActive()){
       it->process(gfx, renderer);
   }
}
\end{verbatim}

Cada algoritmo deve implementar a interface \texttt{SceneProcessor}, que tem os seguintes métodos:

\begin{itemize}
\item \texttt{bool isInitialized(GraphicAPI*)}: método que indica se o algoritmo já preparou todas as suas dependências
\item \texttt{void initialize(GraphicAPI*, Renderer*)}: esse método deve criar todas as dependencias do método \texttt{process}
\item \texttt{void process(GraphicAPI*, Renderer*)}: executa o algoritmo de processamento
\item \texttt{bool isActive()}: indica se o algoritmo deve ou não ser executado
\end{itemize}

\subsubsection{Fase de pós-processamento}

Essa fase é semelhante à anterior, porém o teste de profundidade do fragmento não é executado por padrão, a implementação do algoritmo deve ativá-lo manualmente.

A interface que deve ser implementada é a \texttt{ScenePostProcessor} que define métodos com a mesma semântica dos métodos do \texttt{SceneProcessor}.

\subsubsection{Algoritmos de processamento de cena pré-definidos}

A engine atualmente define apenas um algoritmo de processamento padrão, o \texttt{RenderPassProcessor}. Esse algoritmo utiliza \texttt{ColorPassVisitor} para renderizar os nós do grafo de cena.

\subsubsection{Algoritmos de pós-processamento de cena pré-definidos}
 
Atualmente existem 2 algoritmos de pós-processamento implementados pelas classes: \texttt{FramebufferImageProcessor} e \texttt{BlitToFramebuffer}.

O \texttt{FramebufferImageProcessor} é utilizado para fazer o pós-processamento da imagem que estiver no buffer chamado color dentro do \texttt{FramebufferObject} atual. O algoritmo executado por esse objeto é descrito pelo código abaixo:

\begin{verbatim}
void FramebufferImageProcessor::process(GraphicAPI *gfx, Renderer *renderer) {
    std::map<std::string, Texture2D*> & renderables = renderer->getRenderables();
    Texture2D * auxBuffer = renderables["color_aux"];
    Texture2D * colorBuffer = renderables["color"];
    renderables["color"] = auxBuffer;
    renderables["color_aux"] = colorBuffer;
    FramebufferObject * fbo = renderer->getFramebufferObject();
    fbo->removeRenderable("color");
    fbo->addRenderable(auxBuffer, "color");
    fbo->update(gfx);
    UniformSampler2D* sampler = 
        dynamic_cast<UniformSampler2D*>(gfx->getUniformValue(UniformInfo("color", pbge::SAMPLER_2D)));
    sampler->setValue(colorBuffer);
    renderer->renderScreenQuad(program.get());
}
\end{verbatim}

O \texttt{BlitToFramebuffer} renderiza um retângulo com as dimensões da janela com a textura de nome \texttt{"color"} armazenada no renderizador. É utilizado para renderizar a imagem armazenada na textura color para o framebuffer do sistema de janelas.

\subsubsection{Algoritmos de pós-processamento customizados}

Foram desenvolvidos alguns algoritmos de pós-processamento customizados como exemplo. Eles estão disponíveis na aplicação de visualização de campos tensoriais. A implementação de cada algoritmo se resume a um fragment shader utilizado para instanciar um \texttt{FramebufferImageProcessor}. Esse fragment shader recebe a posição do fragmento e uma textura contendo a imagem a ser renderizada.

\begin{itemize}
\item \textbf{Inversor de cores:} O algoritmo de inversão de cores cria um vetor com os componentes \texttt{r,g,b}, calcula seu complemento e utiliza o resultado como a cor do fragmento:
\begin{verbatim}
pbge::FramebufferImageProcessor * colorInversor() {
    return new pbge::FramebufferImageProcessor(
        "uniform sampler2D color;\n"
        "varying vec2 position;\n"
        "void main() {\n"
        "   vec3 color = (texture2D(color, position.xy)).rgb;\n"
        "   color = 1 - color;\n"
        "   gl_FragColor = vec4(color, 1);\n"
        "}\n"
    );
}
\end{verbatim}
\item \textbf{Filtro de vermelho:} O filtro lê o componente veremelho da cor enviada pelo vertex shader e a utiliza no fragmento, sendo todos os outros componentes iguais a zero:
\begin{verbatim}
pbge::FramebufferImageProcessor * chooseRed() {
    return new pbge::FramebufferImageProcessor(
        "uniform sampler2D color;\n"
        "varying vec2 position;\n"
        "void main() {\n"
        "   float r = (texture2D(color, position.xy)).r;\n"
        "   gl_FragColor = vec4(r, 0, 0, 1);\n"
        "}\n"
    );
}
\end{verbatim}
\item \textbf{Lente senoidal:} A posição $(x_0, y_0)$ recebida é tal que $0 \leq x_0, y_0 \leq 1$. Ela é então mapeada para $(x_1, y_1)$, onde $-1 \leq x_0, y_0 \leq 1$. É calculado então o seno das componentes $x,y$ da posição multiplicadas por um fator que aumenta o efeito da lente. O resultado pertence ao intervalo $[-1,1]$, entretanto as coordenadas de textura estão no intervalo $[0,1]$. Por esse motivo o seno é multiplicado por $0.5$ e somado a $0.5$ resultando em um valor no mesmo intervalo das coordenadas de textura. Esse valor é utilizado para ler uma posição com um pequeno deslocamento da posição do fragmento atual, com isso é gerada uma leve deformação que simula o efeito de uma lente:
\begin{verbatim}
pbge::FramebufferImageProcessor * senoidalLens() {
    return new pbge::FramebufferImageProcessor(
        "varying vec2 position;\n"
        "uniform sampler2D color;\n"
        "void main(){\n"
        "   vec2 x = 2 * position - 1.0;\n"
        "   gl_FragColor = texture2D(color, 0.5 + 0.5 * sin(1.5 * x));\n"
        "}"
    );
}
\end{verbatim}
\end{itemize}

\subsection{Mecanismos da Engine}

\subsubsection{Passagem de parâmetros para o GPUProgram}

A customização do pipeline através de shaders gera grande flexibilidade, porém essa customização só é interessante devido a possibilidade de passagem de diferentes parâmetros para o shader.

Um programa do OpenGL pode receber dois tipos de parâmetros:

\begin{itemize}
\item Uniformes: um valor que é constante para uma dada primitiva, por exemplo, para um triângulo, o processamento de seus três vértices utilizam o mesmo valor de uniforme.
\item Atributos: um valor que é constante para um vértice. Atributos só podem ser acessados dentro do \texttt{vertex shader}. No exemplo acima, cada um dos vértices do triângulo poderia ter um valor diferente para o atributo.
\end{itemize}

No OpenGL, as uniformes são enviadas de forma homogênea através da seguinte rotina:

\begin{verbatim}
// troca o programa associado ao contexto de renderização
glUseProgram(programID);
// localização da uniforme dentro do programa
GLint location = glGetUniformLocation(programID, nome_da_uniforme);
// Existe uma função da família glUniform* para cada tipo de atributo.
// Além disso, para o caso de vetores de valores, existem as funções 
// cujo nome tem o sufixo v, por exemplo, glUniform1fv
// no caso de um float:
glUniform1f(location, valor);
\end{verbatim}

Para atributos, o processo é semelhante:

\begin{verbatim}
glUseProgram(programID);
// localização do atributo dentro do programa
GLint location = glGetAttribLocation(programID, nome_do_atributo);
// Existe uma função da família glVertexAttrib* para cada tipo de atributo.
// Além disso, para o caso de vetores de valores, existem as funções 
// cujo nome tem o sufixo v, por exemplo, glVertexAttrib1fv
// no caso de um float:
glVertexAttrib1f(location, valor);
\end{verbatim}

Dentro da Pandora's Box, o mecanismo de passagem de parâmetros para o shader é implementado através do \texttt{UniformSet}, \texttt{UniformStack}, \texttt{GPUProgram}, \texttt{UniformValue}, \texttt{AttribBinder} e \texttt{BuiltInUniformBinder}.

Como foi citado anteriormente, a última etapa da atualização de estados é a sincronização dos parâmetros do shader. Nessa fase, inicialmente, cada um dos \texttt{UniformInfo} gerados durante a compilação do shader é utilizado para buscar um \texttt{UniformValue} dentro da \texttt{UniformStack}, o uniform value encontrado é então associado ao programa através do mecanismo ilustrado no código abaixo para o caso do GPUProgram implementado para OpenGL:

\begin{verbatim}
void GLProgram::updateUniforms(GraphicAPI * gfx) {
    std::vector<UniformBindAndInfo>::iterator it;
    for(it = uniforms.begin(); it != uniforms.end(); it++) {
        UniformValue * value = gfx->searchUniform(it->getInfo());
        if(it->shouldUpdate(value)) {
            it->update(value);
            value->bindValueOn(this, it->getInfo(), gfx);
        }
    }
    

// cada um dos tipos de UniformValue tem um método de associação
// específico no GPUProgram
// Para o caso do UniformFloat:
void UniformFloat::bindValueOn(GPUProgram *p, const UniformInfo & info, GraphicAPI *ogl) {
    float * values = static_cast<float *>(getValueAt(0));
    p->bindFloat(info, ogl, values, std::min(getNumberOfElements(), info.getNumberOfElements()));
}
\end{verbatim}

% Talvez não citar todas as matrizes. Colocar referencias.

Após essa etapa de associação de valores, os valores uniformes \texttt{built-in} são enviados ao shader. O envio de \texttt{built-in}s é feito através dos \texttt{BuiltInUniformBinder}, que são classes especializadas para cada um dos tipos de valor built-in (atualmente apenas as matrizes gl\_ProjectionMatrix, gl\_ModelViewMatrix, gl\_ModelViewProjectionMatrix, pbge\_ProjectionMatrix, pbge\_ViewMatrix, pbge\_ModelViewMatrix, pbge\_ModelViewProjectionMatrix têm um \texttt{BuiltInUniformBinder} associado).

Os \texttt{BuiltInUniformBinder} implementados na Pandora's Box são de dois tipos:

\begin{itemize}

% Verificar a palavra "binder". Tem lugares que esta com texttt e outros não.

\item \texttt{binder} de variável obsoleta: são classes que enviam para o shader uniformes que foram extintas por versões novas do OpenGL (gl\_ProjectionMatrix, gl\_ModelViewMatrix e gl\_ModelViewProjectionMatrix). Esses \texttt{binder}s utilizam-se das funções obsoletas \texttt{glMatrixMode} e \texttt{glLoadMatrix} para enviar valores ao shader. Por exemplo, no caso da DeprModelViewProjectionBinder que envia o valor da matriz gl\_ModelViewProjection:
\begin{verbatim}
void DeprModelViewProjectionBinder::bind(pbge::GraphicAPI *gfx) {
    math3d::matrix44 projection = gfx->getProjectionMatrix()->get().transpose();
    math3d::matrix44 modelView = (gfx->getViewMatrix()->get() * gfx->getModelMatrix()->get()).transpose();
    glMatrixMode(GL_MODELVIEW);
    glLoadMatrixf(modelView);
    glMatrixMode(GL_PROJECTION);
    glLoadMatrixf(projection);
}
\end{verbatim}

\item \texttt{binder} de \texttt{built-in} da Pandora's Box: são classes que enviam para o shader variáveis que tem significado especial para a engine desenvolvida (pbge\_ProjectionMatrix, pbge\_ViewMatrix, pbge\_ModelViewMatrix e pbge\_ModelViewProjectionMatrix). Esses binders utilizam-se da função glUniformMatrix4fv, que tem a mesma funcionalidade glUniform1f, porém para matrizes. Os \texttt{binder}s dessa categoria são implementados pelo template texttt{MatrixBinder}:
\begin{verbatim}
template<typename MatrixGetter>
class MatrixBinder : public BuiltInUniformBinder {
public:
    MatrixBinder(GLint _location) : location(_location) {}

    void bind(GraphicAPI * gfx) {
        if(getter.shouldChange(gfx)) {
            math3d::matrix44 m = getter(gfx);
            glUniformMatrix4fv(location, 1, GL_TRUE, m);
        }
    }
private:
    MatrixGetter getter;
    
    GLint location;
};
\end{verbatim}
Esse template envia uma matriz para a uniforme localizada identificada por \_location e utiliza-se de um MatrixGetter para conseguir o valor que deve ser enviado. Por exemplo, para o caso do pbge\_ModelViewProjectionMatrix, temos o \texttt{MatrixGetter}:
\begin{verbatim}
class ModelViewProjectionMatrixGetter {
public:
    const math3d::matrix44 operator() (GraphicAPI* gfx) {
        viewStamp = gfx->getViewMatrix()->getStamp();
        modelStamp = gfx->getModelMatrix()->getStamp();
        projStamp = gfx->getProjectionMatrix()->getStamp();
        math3d::matrix44 view = gfx->getViewMatrix()->get();
        math3d::matrix44 model = gfx->getModelMatrix()->get();
        math3d::matrix44 projection = gfx->getProjectionMatrix()->get();
        return projection * view * model;
    }
    bool shouldChange(GraphicAPI * gfx) {
        return viewStamp != gfx->getViewMatrix()->getStamp() ||
               modelStamp != gfx->getModelMatrix()->getStamp() ||
               projStamp != gfx->getProjectionMatrix()->getStamp();
    }
private:
    unsigned long viewStamp, modelStamp, projStamp;
};
\end{verbatim}
\end{itemize}

O mecanismo para o envio dos atributos é semelhante ao utilizada para enviar as uniformes \texttt{built-in}. Cada um dos tipos de atributo definidos na \texttt{enum} \texttt{pbge::VertexAttrib::Type} tem uma classe (\texttt{AttrBinder}) especializada em associar o atributo ao shader.

Os \texttt{AttrBinder}s pertencem à uma das três categorias abaixo:

\begin{itemize}

\item binder de atributo obsoleto: Atributos obsoletos são aqueles que existiam na linguagem de shader GLSL mas que foram removidos em versões mais recentes. A Pandora's Box oferece suporte aos seguintes atributos obsoletos: gl\_Vertex, gl\_Normal, gl\_Color e gl\_SecondaryColor.

No caso do atributo gl\_Vertex, temos o seguinte binder:

\begin{verbatim}
class DeprVertexBinder : public AttrBinder {
public:
    void bind(VertexBuffer * attrs) {
        VertexAttrib * attr = attrs->findByType(VertexAttrib::VERTEX);
        glEnableClientState(GL_VERTEX_ARRAY);
        glVertexPointer(attr->getNCoord(), GL_FLOAT, attr->getStride(), ATTRIB_POINTER_OFFSET(attr->getOffset()));
    }

    void unbind() {
        glDisableClientState(GL_VERTEX_ARRAY);
    }
};
\end{verbatim}

\item binder de atributo definido pela engine: A Pandora's Box define os seguintes atributos: pbge\_Vertex, pbge\_Normal, pbge\_Color e pbge\_SecondaryColor, sendo que todos esses atributos enviados para o shader através da classe \texttt{SemanticAttribBinder}:

\begin{verbatim}
class SemanticAttribBinder : public AttrBinder {
public:
    SemanticAttribBinder(const VertexAttrib::Type attrType, GLint attrLocation): type(attrType), location(attrLocation){}

    void bind(VertexBuffer * attrs) {
        VertexAttrib * attr = attrs->findByType(type);
        glVertexAttribPointer(location, attr->getNCoord(), GL_FLOAT, GL_FALSE, attr->getStride(), ATTRIB_POINTER_OFFSET(attr->getOffset()));
        glEnableVertexAttribArray(location);
    }

    void unbind() {
        glDisableVertexAttribArray(location);
    }
private:
    VertexAttrib::Type type;
    GLint location;
};
\end{verbatim}

\item binder de atributo definido pelo usuário da engine: Esses atributos são mapeados para o shader através do \texttt{CustomAttrBinder}:

\begin{verbatim}
class CustomAttrBinder : public AttrBinder {
public:
    CustomAttrBinder(std::string attrName, GLint attrLocation) : name(attrName), location(attrLocation) {}

    void bind(VertexBuffer * attrs) {
        VertexAttrib * attr = attrs->findByName(name);
        glVertexAttribPointer(location, attr->getNCoord(), GL_FLOAT, GL_FALSE, attr->getStride(), ATTRIB_POINTER_OFFSET(attr->getOffset()));
        glEnableVertexAttribArray(location);
    }

    void unbind() {
        glDisableVertexAttribArray(location);
    }
private:
    std::string name;
    GLint location;
};
\end{verbatim}

\end{itemize}

% TODO: mover o mapeamento para antes dos parâmetros do shader
\subsubsection{Mapeamento e gerenciamento dos estados}

Em placas de vídeo modernas, dispositivos altamente paralelos, as trocas de estado podem fazer com que o pipeline gráfico tenha que ser esvaziado, o que pode causar um grande impacto no desempenho da aplicação, por isso, é necessário evitar trocas de estado redundantes, minimizar trocas de estado e agrupar as trocas de estado.

Na Pandora's Box, esse trabalho é delegado à classe \texttt{StateSet} e à algumas classes controladoras menores. A \texttt{StateSet} é uma classe que controla os objetos que estão associados ao contexto gráfico.

\subsubsection{Desenho de modelos}

Existem 2 modos de se enviar vértices para serem processados pelo pipeline, através de \texttt{VertexBuffer} ou através de chamadas de função obsoletas definidas pelo OpenGL, além disso, algumas vezes deseja-se que um mesmo modelo seja renderizado diversas vezes em um loop (instanced draw). Para lidar com essas situações, a Pandora's Box utiliza a classe \texttt{DrawController}.

O \texttt{DrawController} é responsável por enviar corretamente ao pipeline modelos definidos por instâncias de \texttt{VertexBuffer} (na engine tais modelos são instâncias de \texttt{VBOModel}) assim como instâncias de modelos que utilizam as funções obsoletas. Além de gerenciar a renderização de um modelo, o \texttt{DrawController} é responsável por implementar o instanced draw.

Na Pandora's Box, instanced draw é implementado de forma nativa para \texttt{VBOModel}, ou seja, utilizando-se as funções específicas do OpenGL que implementam a técnica, e de forma simulada se o modelo não for instância de VBOModel. A versão simulada da técnica é conhecida como pseudo-instanciação. Em ambas as versões, uma variável que indica qual é a instância do modelo que está atualmente sendo renderizada. Essa técnica pode ser ilustrada pelo código abaixo:

\begin{verbatim}
GraphicAPI * gfx = ...;
Model * model = ...;
// prepara o modelo para a renderização
model->beforeRender(gfx);
for(int i = 0; i < number_of_instances; i++) {
    int instanceID = i;
    // renderiza a instância instanceID
    // a variável instanceID fica disponível no vertex shader
    model->render(gfx)
}
model->afterRender(gfx);
instanceID = 0;
\end{verbatim}

\subsection{Visualização de campos tensoriais}

A aplicação de visualização de campos tensoriais é dividida em duas etapas:

% Tirar o textregistered e colocar uma referencia para o formato

\begin{itemize}
\item Compilação do formato Analyze~\cite{Analyze} para o formato \texttt{.ctf}
(Compiled Tensor Field)
\item Apresentação do campo contido no arquivo \texttt{.ctg}
\end{itemize}

\subsubsection{O formato Analyze}

O formato Analyze é um formato de armazenamento de informações de imagens de ressonância magnética. A informação é dividida em dois arquivos: um cabeçalho (extensão \texttt{.hdr}) com informações sobre o campo (dimensões, ordenação, identificação e histórico) e o arquivo de imagem (extensão \texttt{.img}) contendo somente os valores da imagem (organizados conforme a descrição do cabeçalho).

Para o desenvolvimento do leitor de arquivos Analyze foi feita a suposição de que os nomes dos arquivos (\texttt{.hdr} e \texttt{.img}) são iguais visando simplificar a utilização e implementação.

\subsubsection{O formato Compiled Tensor Field (.ctf)}

O formato Compiled Tensor Field (\texttt{.ctf}) foi desenvolvido para armazenamento de informações sobre o campo tensorial a ser mostrado na aplicação de visualização de campos tensoriais. É um formato binário que contém o número de elipsóides (representação visual do tensor) no arquivo seguido por um conjunto de matrizes de transformação linear. Cada matriz será aplicada a uma esfera para obter um elipsóide na posição correta no campo. Por esse motivo ela contém uma escala (proporcional aos autovalores do tensor aplicados nos eixos cartesianos), uma rotação (dos eixos cartesianos para os eixos definidos pelos autovetores do tensor) e uma translação (para posicionar o elipsóide corretamente no campo).

Na etapa de compilação a imagem de ressonância magnética é lida e os tensores armazenados em um vetor. Dada a seguinte definição para um tensor $A$ $3 \times 3$ nulo (para um dado $\varepsilon > 0$) para $1 \leq i, j \leq 3$, $i, j \in \mathbb{I}$:

% Explicar melhor essa definição. Usar "Um tensor A sera considerado nulo quando ... for valido" por exemplo

\begin{math}
|A_{i,j}| < \varepsilon
\end{math}

Todos os tensores nulos são ignorados na compilação. São então calculados os autovalores e autovetores de todos os tensores não nulos, geradas as matrizes de transformação linear que levam uma esfera centralizada na origem para um elipsóide na posição correta no campo e armazenadas em um vetor. 

Como tais matrizes são matrizes de transformação homogênea, sabemos que a última linha sempre será $(0,0,0,1)$. Assim é possível ocultar tais dados e enviar outras informações em seu lugar (é necessário substituir os valores dessa linha para realizar quaisquer operações com a matriz). Nessa linha são armazenados os valores das equações (\ref{af}), (\ref{linearCase}), (\ref{planarCase}) e (\ref{sphericalCase}) (definidas na página \pageref{af}) que serão utilizados como diferentes políticas de escolha de nível de transparência (alfa) e cor dos elipsóides.

As matrizes são então reorganizadas em blocos de proximidade para otimizar a utilização pela aplicação de visualização. O vetor de matrizes reordenado é finalmente escrito no arquivo, além das informações iniciais sobre o campo.

\subsubsection{Apresentação do campo compilado}

O arquivo \texttt{.ctf} é lido e cada bloco de matrizes é enviado como \texttt{uniform} para o \texttt{shader} que as aplica a esferas. A política de transparência (alfa) dos elipsóides é escolhida pelo usuário, sendo o valor de alfa algum dos quatro resultados das equações de anisotropia fracionada. A cor aplicada a cada elipsóide é calculada a partir do valor de alfa em uma rampa de cores também definida pelo usuário.

\begin{center}
\begin{longtable}{cc}
\epsfig{file=cerebro1.eps, width=0.47\textwidth,clip=} &
\epsfig{file=cerebro2.eps, width=0.47\textwidth,clip=}
\end{longtable}
\vspace{-15pt}
\parbox{0.98\textwidth}{\captionof{figure}{Imagens da
visualização do campo tensorial de um cérebro humano. As cores são aplicadas a partir do valor de
anisotropia fracionada em uma rampa de cores que varia do azul (menor
anisotropia) para o amarelo (maior anisotropia).}}
\end{center}

Para a translação e rotação do campo foram implementados um \texttt{KeyboardEventHandler} e um \texttt{MouseEventHandler} respectivamente que atualizam os nós de transformação.

\subsection{Técnicas aplicadas}

\subsubsection{Depth Peeling}
No campo tensorial em diversos casos existem elipsóides sobrepostos. Para observar alguns tipos de estrutura é interessante que tais elipsóides possuam algum nível de transparência. Para isso é necessário simular a transparência através de combinações de cores sobrepostas. Existem técnicas~\cite{alphasorting} que dependem dos objetos serem renderizados dos mais distantes para os mais próximos da câmera, entretanto no caso do campo esse tipo de processo se torna muito lento devido à grande quantidade de objetos a serem ordenados antes de cada renderização. Por esse motivo é necessário algum algoritmo independente da ordem de renderização.

Depth peeling~\cite{everitt} é uma técnica iterativa que consiste de remoções de camadas próximas a cada iteração. Inicialmente a cena é renderizada normalmente armazenando o color buffer e o depth buffer em buffers auxiliares. A cada nova iteração todos os fragmentos com profundidade menor ou igual à profundidade armazenada no depth buffer auxiliar são descartados. Um novo depth buffer auxiliar é gerado a partir das profundidades dos fragmentos restantes, que são então renderizados e o resultado (color buffer) é acumulado no color buffer auxiliar.

Para a realização da técnica completa são necessárias $N$ iterações, onde $N$ é o número máximo de fragmentos sobrepostos na cena. Entretanto foi fixado um número de iterações para diminuir a complexidade da técnica.

Na aplicação de exemplo o depth peeling foi implementado como um processador de cena sendo que a cada iteração o grafo de cena é percorrido uma vez.

As imagens abaixo exemplificam essa técnica com duas esferas acompanhadas do resultado da iteração.

\begin{wrapfigure}{l}{\textwidth}
\vspace{-20pt}
\begin{center}
\subfigure[Primeira iteração]{\includegraphics[width=0.49\textwidth]{depthpeeling1}}
\subfigure[Segunda iteração]{\includegraphics[width=0.49\textwidth]{depthpeeling2}}
\subfigure[Terceira iteração]{\includegraphics[width=0.49\textwidth]{depthpeeling3}}
\end{center}
\vspace{-20pt}
\caption{Campo de grama}
\vspace{-10pt}
\end{wrapfigure}



\section{Atividades realizadas}
As ideias apresentadas a seguir foram aplicadas no desenvolvimento da engine e da aplicação de visualização de campos tensoriais.

\subsection{Objetos da API gráfica}

Nessa seção serão descritos os mapeamentos utilizados pela engine para os objetos definidos pela API gráfica.
% TODO: O que é a API gráfica

\subsubsection {Bufer}

\subsubsection {Shader}

Como já foi explicado, o OpenGL opera nas primitivas gráficas através de um pipeline, que tem cinco estágios principais: transformação de vértices, tesselagem, criação de novas primitivas, rasterização e operações por fragmento. Até a versão 1.5, esse pipeline tinha funcionalidade fixa. 

A partir da versão 2.0, os \texttt{shaders} foram introduzidos. Um shader é um programa que sobrescreve alguma das funcionalidades fixas do pipeline.

Na Pandora's Box, ....

\subsubsection {GPUProgram}

No OpenGL, programas são grupos de shaders, onde cada fase do pipeline pode ser sobrescrita apenas uma vez, o que implica que os shaders que sobrescrevem um determinado passo do pipeline só podem especificar uma função main.

Na engine, esse mesmo conceito é implementado...

\subsubsection {Texture1D}

\subsubsection {Texture2D}

\subsubsection {BufferTexture}

\subsubsection{VertexBuffer}
% precisa da historinha?
No início da computação gráfica, os vértices eram especificados um a um através de chamadas à API gráfica, por exemplo, a especificação de um triângulo no OpenGL era feita da seguinte forma:

\begin{verbatim}
glBegin(GL_TRIANGLES);
glVertex3f(0.0f, 0.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glVertex3f(0.0f, 1.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glVertex3f(1.0f, 0.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glEnd();
\end{verbatim}

pode-se observar que o número de chamadas de função cresce linearmente com a quantidade de vértices do modelo, além disso cada um dos atributos do vértice (posição, cor, normal, entre outros) era especificado através de uma chamada de função diferente.

Com o aumento da complexidade dos modelos, foi necessário reinventar a API existente, com isso foi criado o conceito de \texttt{vertex array}, que é simplesmente um vetor de valores de tipos variados em que cada atributo é específicado atravez de seu tipo primitivo (double, float, int, short, byte) número de componentes, significado (posição, vetor normal, coordenada de textura, \ldots) e a distância em bytes para o próximo valor desse atributo no vetor. Essa estrutura é exemplificada na figura abaixo.

%todo: colocar uam figura sobre vertex array

Como a especificação desse modelo de dados era flexível e permitia enviar uma grande quantidade de dados para a \texttt{GPU} em um número constante de chamadas de função, ele foi rapidamente adotado pelos programadores.

Mas esse modelo não solucionava o problema de tráfego de dados entre a memória principal (RAM) e a memória de vídeo (VRAM). A solução do problema de tráfego de dados foi colocar o \texttt{vertex array} dentro de um buffer gerenciado pela implementação da API gráfica, assim, a implementação poderia colocar dados muito utilizados dentro de regiões de fácil acesso, como a VRAM. Essa solução ficou conhecida como \texttt{Vertex Buffer}

% como construir com o builder

Na Pandora's Box, \texttt{Vertex Buffers} são especificados através da classe VertexBuffer, sua estrutura interna é semelhante à apresentada na figura X. % não esquecer de referenciar o nome da figura dos vertex buffer
Cada vértice é específicado através da classe VertexAttrib que guarda informações sobre o primeiro índice do atributo dentro o buffer, seu significado, número de componentes e qual a distância entre valores consecutivos do atributo.

A forma recomendada de se criar um \texttt{VertexBuffer} é através do \texttt{VertexBufferBuilder}. % falar mais sobre o vertexbufferbuilder

\subsubsection {FrameBufferObject}

\subsection{Grafo de cena}
%TODO: Geral sobre o que é o grafo de cena, como é percorrido, etc.

\subsubsection{Tipos de nós}

\subsubsection{Node Visitors}

%TODO: O que é um visitor (referencia pro GOF só?)
Todos os \texttt{Visitors} padrão da engine herdam da classe abstrata \texttt{VisitorTrait}, que encapsula o algoritmo de busca em profundidade para grafos direcionados. 
Cada \texttt{visitor} é responsável por executar um determinado conjunto de métodos durante sua travessia no grafo de cena.

%checar os nomes dos visitors pq eu realmente não me lembro....
Os \texttt{visitors} definidos pela engine são: \texttt{UpdatePassVisitor} e \texttt{ColorPassVisitor}.

% O que é o UpdatePass do renderizador? Vai estar explicado antes?
% É executado o updatePass do nó?
O \texttt{UpdatePassVisitor} é responsável por fazer a travessia dentro do \texttt{UpdatePass} do renderizador. Durante a travessia esse visitor executa o método \texttt{updatePass} e em seguida continua a busca em profundidade e, por fim, executa o método \texttt{postUpdatePass}.

% Pensar melhor nesse nome
% Citar artigo da NVidia
Geometry instancing

\subsection{Renderizador}

O renderizador da engine gráfica utiliza um algoritmo de 3 fases:

\begin{itemize}
\item Atualização dos nós do grafo de cena
\item Processamento do grafo de cena
\item Pós-Processamento da imagem gerada pela fase de processamento
\end{itemize}

\subsubsection {Fase de atualização}
% Acho que essa explicação precisa acontecer antes da explicação sobre os NodeVisitors

Nessa fase cada nó do grafo de cena é atualizado através de uma chamada ao método updatePass da interface Node.

Para a implementação dessa fase foi utilizado o \texttt{Visitor}, % não esquecer de colocar referencia para o GOF aqui
que implementa uma busca em profundidade no grafo de cena. Essa é a única parte do algoritmo de renderização que não pode ser customizada.

\subsubsection {Fase de processamento do grafo de cena}

Nessa fase executa-se uma sequência de algoritmos definida pelo usuário da engine, a execução é equivalente ao código:

%verificar se os argumentos estão corretos
\begin{verbatim}
std::vector<SceneProcessor*>::iterator it;
for(it = processors.begin(); it != processors.end(); it++){
   if(it->isActive()){
       it->process(gfx, renderer);
   }
}
\end{verbatim}

Cada algoritmo deve implementar a interface \texttt{SceneProcessor}, que tem os seguintes métodos:

\begin{itemize}
\item \texttt{bool isInitialized(GraphicAPI*)}: método que indica se o algoritmo já preparou todas as suas dependências
\item \texttt{void initialize(GraphicAPI*, Renderer*)}: esse método deve criar todas as dependencias do método \texttt{process}
\item \texttt{void process(GraphicAPI*, Renderer*)}: executa o algoritmo de processamento
\item \texttt{bool isActive()}: indica se o algoritmo deve ou não ser executado
\end{itemize}

\subsubsection{Fase de pós-processamento}

%Em algum lugar vai ser explicado o que é o teste de profundidade do fragmento?
Essa fase é semelhante à anterior, porém o teste de profundidade do fragmento não é executado por padrão, a implementação do algoritmo deve ativá-lo manualmente.

A interface que deve ser implementada é a \texttt{ScenePostProcessor} que define métodos com a mesma semântica dos métodos do \texttt{SceneProcessor}.

\subsubsection{Algoritmos de processamento de cena pré-definidos}

A engine atualmente define apenas um algoritmo de processamento padrão, o \texttt{ColorPass}. % checar o nome do algoritmo

Esse algoritmo executa uma busca em profundidade no grafo de cena executando o método \texttt{colorPass} de cada nó. %Mudar se implementarmos o frustum culling

\subsubsection{Algoritmos de pós-processamento de cena pré-definidos}
 
Atualmente existem 2 algoritmos de pós-processamento implementados pelas classes: \texttt{FramebufferImageProcessor} e \texttt{BlitToFramebuffer}.

O \texttt{FramebufferImageProcessor} implementa uma técnica de renderização conhecida como ping-pong rendering. % achar o termo técnico correto
% descrever a técnica e a implementação.

O \texttt{BlitToFramebuffer} renderiza um retângulo com as dimensões da tela com a textura de nome \texttt{"color"} armazenada no renderizador.
% blit to framebuffer

\subsubsection{Algoritmos de pós-processamento customizados}

Foram desenvolvidos alguns algoritmos de pós-processamento customizados como exemplo. Eles estão disponíveis na aplicação de visualização de campos tensoriais. % Explicar direito e listar os exemplos

\subsection{Mecanismos da Engine}

\subsubsection{Passagem de parâmetros para o GPUProgram}

A customização do pipeline através de shaders gera grande flexibilidade, porém essa customização só é interessante por causa da passagem de diferentes parâmetros para o shader.

Um programa do OpenGL pode receber dois tipos de parâmetros:

\begin{itemize}
\item Uniformes: um valor que é constante para uma dada primitiva, por exemplo, para um triângulo, o processamento de seus três vértices utilizam o mesmo valor de uniforme.
\item Atributos: um valor que é constante para um vértice. Atributos só podem ser acessados dentro do \texttt{vertex shader}. No exemplo acima, cada um dos vértices do triângulo poderia ter um valor diferente para o atributo.
\end{itemize}

No OpenGL, as uniformes são enviadas de forma homogênea através da seguinte rotina:

\begin{verbatim}
// troca o programa associado ao contexto de renderização
glUseProgram(programID);
// localização da uniforme dentro do programa
GLint location = glGetUniformLocation(programID, nome_da_uniforme);
// Existe uma função da família glUniform* para cada tipo de atributo.
// Além disso, para o caso de vetores de valores, existem as funções 
// cujo nome tem o sufixo v, por exemplo, glUniform1fv
// no caso de um float:
glUniform1f(location, valor);
\end{verbatim}

Para atributos, o processo é semelhante:

\begin{verbatim}
glUseProgram(programID);
// localização do atributo dentro do programa
GLint location = glGetAttribLocation(programID, nome_do_atributo);
// Existe uma função da família glVertexAttrib* para cada tipo de atributo.
// Além disso, para o caso de vetores de valores, existem as funções 
// cujo nome tem o sufixo v, por exemplo, glVertexAttrib1fv
// no caso de um float:
glVertexAttrib1f(location, valor);
\end{verbatim}

Dentro da Pandora's Box, o mecanismo de passagem de parâmetros para o shader é implementado através do \texttt{UniformSet}, \texttt{UniformStack}, \texttt{GPUProgram}, \texttt{UniformValue}, \texttt{AttribBinder} e \texttt{BuiltInUniformBinder}.

Como foi citado anteriormente, a última etapa da atualização de estados é a sincronização dos parâmetros do shader. Nessa fase, inicialmente, cada um dos \texttt{UniformInfo} gerados durante a compilação do shader é utilizado para buscar um \texttt{UniformValue} dentro da \texttt{UniformStack}, o uniform value encontrado é então associado ao programa através do mecanismo ilustrado no código abaixo para o caso do GPUProgram implementado para OpenGL:

\begin{verbatim}
void GLProgram::updateUniforms(GraphicAPI * gfx) {
    std::vector<UniformBindAndInfo>::iterator it;
    for(it = uniforms.begin(); it != uniforms.end(); it++) {
        UniformValue * value = gfx->searchUniform(it->getInfo());
        if(it->shouldUpdate(value)) {
            it->update(value);
            value->bindValueOn(this, it->getInfo(), gfx);
        }
    }
    

// cada um dos tipos de UniformValue tem um método de associação
// específico no GPUProgram
// Para o caso do UniformFloat:
void UniformFloat::bindValueOn(GPUProgram *p, const UniformInfo & info, GraphicAPI *ogl) {
    float * values = static_cast<float *>(getValueAt(0));
    p->bindFloat(info, ogl, values, std::min(getNumberOfElements(), info.getNumberOfElements()));
}
\end{verbatim}

Após essa etapa de associação de valores, os valores uniformes \texttt{built-in} são enviados ao shader. O envio de \texttt{built-in}s é feito através dos \texttt{BuiltInUniformBinder}, que são classes especializadas para cada um dos tipos de valor built-in (atualmente apenas as matrizes gl\_ModelViewMatrix, gl\_ModelViewProjectionMatrix, pbge\_ViewMatrix, pbge\_ModelViewMatrix, pbge\_ModelViewProjectionMatrix têm um \texttt{BuiltInUniformBinder} associado). 


% explicar o uniform set e o uniform stack e os tipos suportados
% tradução de atributos para o shader


% TODO: mover o mapeamento para antes dos parâmetros do shader
\subsubsection{Mapeamento dos estados}

Para minimizar o número de troca de estados do OpenGL, a Pandora's Box possui a classe \texttt{StateSet}. Essa classe representa quais objetos estão associados ao contexto corrente da API gráfica. % lazy state
%explicar o state set e os state controller(depthcontroller e blendcontroller)

\subsubsection{Desenho de modelos}

Para lidar com a variedade de tipos de modelos e com as diferentes técnicas de renderização, foi desenvolvido um controlador de desenho.

A implementação dessa classe utilizando OpenGL 
% introdução ao drawcontroller
%explicar a implementação para um model generico
% explicar a implementação para VBOModel
% explicar a implementação do render instanced

\subsection{Visualização de campos tensoriais}

A aplicação de visualização de campos tensoriais é dividida em duas etapas:

\begin{itemize}
\item Compilação do formato Analyze\textregistered  para o formato \texttt{.ctf} (Compiled Tensor Field)
\item Apresentação do campo contido no arquivo \texttt{.ctg}
\end{itemize}

\subsubsection{O formato Analyze\textregistered}

O formato Analyze\textregistered\space é um formato de armazenamento de informações de imagens de ressonância magnética. A informação é dividida em dois arquivos: um cabeçalho (extensão \texttt{.hdr}) com informações sobre o campo (dimensões, ordenação, identificação e histórico) e o arquivo de imagem (extensão \texttt{.img}) contendo somente os valores da imagem (organizados conforme a descrição do cabeçalho).

Para o desenvolvimento do leitor de arquivos Analyze\textregistered\space foi feita a suposição de que os nomes dos arquivos (\texttt{.hdr} e \texttt{.img}) são iguais visando simplificar a utilização e implementação. % Mudar isso se mudar o código

\subsubsection{O formato Compiled Tensor Field (.ctf)}

O formato Compiled Tensor Field (\texttt{.ctf}) foi desenvolvido para armazenamento de informações sobre o campo tensorial a ser mostrado na aplicação de visualização de campos tensoriais. É um formato binário que contém o número de elipsóides (representação visual do tensor) no arquivo seguido por um conjunto de matrizes de transformação linear. Cada matriz será aplicada a uma esfera para obter um elipsóide na posição correta no campo. Por esse motivo ela contém uma escala (proporcional aos autovalores do tensor aplicados nos eixos cartesianos), uma rotação (dos eixos cartesianos para os eixos definidos pelos autovetores do tensor) e uma translação (para posicionar o elipsóide corretamente no campo).

\subsubsection{Compilação da imagem de ressonância magnética}

Na etapa de compilação a imagem de ressonância magnética é lida e os tensores armazenados em um vetor. Dada a seguinte definição para um tensor $A$ $3 \times 3$ nulo (para um dado $\varepsilon > 0$) para $1 \leq i, j \leq 3$, $i, j \in \mathbb{I}$:

\begin{math}
|A_{i,j}| < \varepsilon
\end{math}

Todos os tensores nulos são ignorados na compilação. São então calculados os autovalores e autovetores de todos os tensores não nulos, geradas as matrizes de transformação linear que levam uma esfera centralizada na origem para um elipsóide na posição correta no campo e armazenadas em um vetor. 

Como tais matrizes são matrizes de transformação homogênea, sabemos que a última linha sempre será $(0,0,0,1)$. Assim é possível ocultar tais dados e enviar outras informações em seu lugar (é necessário substituir os valores dessa linha para realizar quaisquer operações com a matriz). Nessa linha são armazenados os valores das equações (\ref{af}), (\ref{linearCase}), (\ref{planarCase}) e (\ref{sphericalCase}) (definidas na página \pageref{af}) que serão utilizados como diferentes políticas de escolha de nível de transparência (alfa) e cor dos elipsóides.

As matrizes são então reorganizadas em blocos de proximidade para otimizar a utilização pela aplicação de visualização. O vetor de matrizes reordenado é finalmente escrito no arquivo, além das informações iniciais sobre o campo.

\subsubsection{Apresentação do campo compilado}

O arquivo \texttt{.ctf} é lido e cada bloco de matrizes é enviado como \texttt{uniform} para o \texttt{shader} que as aplica a esferas. A política de transparência (alfa) dos elipsóides é escolhida pelo usuário, sendo o valor de alfa algum dos quatro resultados das equações de anisotropia fracionada. A cor aplicada a cada elipsóide é calculada a partir do valor de alfa em uma rampa de cores também definida pelo usuário.

Para a translação e rotação do campo foram implementados um \texttt{KeyboardEventHandler} e um \texttt{MouseEventHandler} respectivamente que atualizam os nós de transformação.

\subsection{Técnicas aplicadas}

\subsubsection{Depth Peeling}
No campo tensorial em diversos casos existem elipsóides sobrepostos. Para observar alguns tipos de estrutura é interessante que tais elipsóides possuam algum nível de transparência. Para isso é necessário simular a transparência através de combinações de cores sobrepostas. Existem técnicas~\cite{alphasorting} que dependem dos objetos serem renderizados dos mais distantes para os mais próximos da câmera, entretanto no caso do campo esse tipo de processo se torna muito lento devido à grande quantidade de objetos a serem ordenados antes de cada renderização. Por esse motivo é necessário algum algoritmo independente da ordem de renderização.

Depth peeling~\cite{everitt} é uma técnica iterativa que consiste de remoções de camadas próximas a cada iteração. Inicialmente a cena é renderizada normalmente armazenando o color buffer e o depth buffer em buffers auxiliares. A cada nova iteração todos os fragmentos com profundidade menor ou igual à profundidade armazenada no depth buffer auxiliar são descartados. Um novo depth buffer auxiliar é gerado a partir das profundidades dos fragmentos restantes, que são então renderizados e o resultado (color buffer) é acumulado no color buffer auxiliar.

Para a realização da técnica completa são necessárias $N$ iterações, onde $N$ é o número máximo de fragmentos sobrepostos na cena. Entretanto foi fixado um número de iterações para diminuir a complexidade da técnica.

Na aplicação de exemplo o depth peeling foi implementado como um processador de cena sendo que a cada iteração o grafo de cena é percorrido uma vez.

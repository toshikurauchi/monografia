

\section{Atividades realizadas}
\label{atividades}
As ideias apresentadas a seguir foram aplicadas no desenvolvimento da engine e da aplicação de visualização de campos tensoriais.

\subsection{Objetos da API gráfica}

Nessa seção serão descritos os mapeamentos utilizados pela engine para os objetos mais comuns definidos pelo OpenGL. Todos os mapeamentos foram projetados de forma que os objetos pudessem ser utilizados fora de um contexto inicializado e, além disso, os o objeto do OpenGL só é instanciado se necessário, o que economiza recursos da placa gráfica.

\subsubsection {Bufer}

Um \texttt{Buffer} é uma região de memória controlado pelo driver gráfico. O conceito de \texttt{Buffer} foi criado para resolver o gargalo da comunicação entre Memória Principal e Memória de Vídeo.

No OpenGL, buffers são criados através da função glGenBuffers. Depois de criado, o buffer deve ser associado ao contexto do OpenGL, para isso utiliza-se o comando glBindBuffer, esse comando, além de informar ao OpenGL que o buffer deve ser associado ao contexto, faz com que os dados presentes no buffer sejam interpretados de forma diferente. Por exemplo, para informar que o buffer será utilizado para fornecer vértices ao pipeline, utiliza-se:

\begin{verbatim}
glBindBuffer(GL_ARRAY_BUFFER);
\end{verbatim}

Com o buffer associado ao contexto, é necessário inicializar os dados do buffer. Essa inicialização é feita pelo comando \texttt{glBufferData}. Após esses procedimentos, o buffer está pronto para ser utilizado.

Uma das características mais importantes do \texttt{buffer} é a possibilidade de mapeá-lo em uma região de memória que pode ser acessada pela aplicação. Esse mapeamento é importante, pois ele permite que a aplicação informe ao OpenGL que política de acesso a aplicação adotará para ler ou escrever na memória mapeada. Por exemplo, se o buffer for mapeado utilizando-se GL\_WRITE\_ONLY, o driver gráfico não precisa copiar os dados da memória do driver para a memória principal, o que diminui a troca de dados entre a memória de vídeo e a memória principal.

As políticas de acesso definidas pelo OpenGL são: 
\begin{itemize}
\item GL\_READ\_ONLY: quando a aplicação planeja apenas ler a região de memória
\item GL\_WRITE\_ONLY: quando a região de memória for utilizada apenas para escrita
\item GL\_READ\_WRITE: quando a memória mapeada for utilizada para leitura e escrita
\end{itemize}

O mapeamento de um vertex buffer que será utilizado somente para escrita pode ser feito através do seguinto código:

\begin{verbatim}
glBindBuffer(GL_ARRAY_BUFFER, bufferID);
void * mappedBuffer = glMapBuffer(GL_ARRAY_BUFFER, GL_WRITE_ONLY);
\end{verbatim}

Após a utilização da região mapeada, é importante cancelar o mapeamento feito. Esse cancelamento é feito através da função \texttt{glUnmapBuffer};

Na \texttt{Pandora's Box}, \texttt{buffer}s são implementações da interface \texttt{Buffer}. O buffer padrão do OpenGL é implementado pela classe GLBuffer:
\begin{verbatim}
// GLBuffer.h
#ifndef PBGE_GRAPHIC_API_GL_BUFFER
#define PBGE_GRAPHIC_API_GL_BUFFER

#include <GL/glew.h>
#include "pbge/gfx/Buffer.h"

namespace pbge {
    class GLGraphic;
    class GLObjectsFactory;

    // TODO: make changes to the buffer interface
    class GLBuffer : public Buffer {
    public:
        friend GLObjectsFactory;

        // returns the data buffer
        void * map(Buffer::AccessPattern access);

        void unmap();

        void unbind();

        void bindOn(Buffer::Target _target);

        GLuint getID() {
            return glID;
        }
    private:
        // retirei o target
        GLBuffer(size_t _size, Buffer::UsageHint _usage, GLGraphic * _gl);
        
        void destroy();

        void initialize();
        
        GLGraphic * gl;

        GLenum usage;

        GLenum target;

        void * data;

        GLuint glID;

        size_t size;
    };
}
#endif
\end{verbatim}
\begin{verbatim}
// GLBuffer.cpp
#include <GL/glew.h>

#include "OpenGLAPI/gfx/GLGraphic.h"
#include "OpenGLAPI/gfx/GLBuffer.h"

using namespace pbge;

GLenum translateUsageHint(Buffer::UsageHint usageHint) {
    GLenum usage;
    switch (usageHint) {
        case Buffer::STREAM_COPY: usage = GL_STREAM_COPY; break;
        case Buffer::STREAM_DRAW: usage = GL_STREAM_DRAW; break;
        case Buffer::STREAM_READ: usage = GL_STREAM_READ; break;

        case Buffer::STATIC_COPY: usage = GL_STATIC_COPY; break;
        case Buffer::STATIC_DRAW: usage = GL_STATIC_DRAW; break;
        case Buffer::STATIC_READ: usage = GL_STATIC_READ; break;

        case Buffer::DYNAMIC_COPY: usage = GL_DYNAMIC_COPY; break;
        case Buffer::DYNAMIC_DRAW: usage = GL_DYNAMIC_DRAW; break;
        case Buffer::DYNAMIC_READ: usage = GL_DYNAMIC_READ; break;
        default: throw 1;
    }
    return usage;
}

GLBuffer::GLBuffer(size_t _size, Buffer::UsageHint _usage, GLGraphic * ogl):size(_size), target(0), glID(0), gl(ogl) {
    this->usage = translateUsageHint(_usage);
    this->data = malloc(size);
    if (this->data == NULL) {
        // error
    }
} 

void * GLBuffer::map(AccessPattern accessPattern) {
    unsigned access = 0;
    if(data != NULL) {
        return data;
    }
    switch(accessPattern) {
        case READ_ONLY: access = GL_READ_ONLY; break;
        case WRITE_ONLY: access = GL_WRITE_ONLY; break;
        case READ_WRITE: access = GL_READ_WRITE; break;
        // TODO: log warn
        default: throw 1;
    }
    glBindBuffer(target, glID);
    return glMapBuffer(target, access);
}

void GLBuffer::unmap() {
    if(data == NULL)
        glUnmapBuffer(target);
}

void GLBuffer::bindOn(Target _target) {
    GLenum bindPoint = 0;
    switch(_target) {
        case Buffer::VertexBuffer: bindPoint = GL_ARRAY_BUFFER; break;
        case Buffer::IndexBuffer: bindPoint = GL_ELEMENT_ARRAY_BUFFER; break;
        case Buffer::PixelReadBackBuffer: bindPoint = GL_PIXEL_PACK_BUFFER; break;
        case Buffer::PixelSendBuffer: bindPoint = GL_PIXEL_UNPACK_BUFFER; break;
        case Buffer::BufferTextureStorage: bindPoint = gl->getExtensions().getBufferTextureInfo().bufferBinding;
    }
    if(bindPoint == 0) {
        throw 1;
    }
    // the default target will be the target of the first bind
    if (this->target == 0) {
        this->target = bindPoint;
    }
    if (this->glID == 0) {
        this->initialize();
    }
    glBindBuffer(bindPoint, glID);
}

void GLBuffer::unbind() {
    glBindBuffer(target, 0);
}

void GLBuffer::initialize() {
    glGenBuffers(1, &glID);
    glBindBuffer(target, glID);
    if (data != NULL) {
        glBufferData(target, size, data, usage);
        delete data;
        data = NULL;
    } else { // maybe allocation failed?
        glBufferData(target, size, NULL, usage);
    }
}

void GLBuffer::destroy() {
    if (glID != 0) {
        glDeleteBuffers(1, &glID);
    }
    if (this->data != NULL) {
        delete data;
    }
}
\end{verbatim}

Exemplo de uso de um \texttt{buffer} da \texttt{Pandora's Box}:
\begin{verbatim}
GraphicAPI *gfx = ...;
// cria um buffer de tamanho size e com política de uso usage
// As políticas de uso permitidas são:
// STREAM_DRAW, STREAM_READ, STREAM_COPY, STATIC_DRAW, STATIC_READ, 
// STATIC_COPY, DYNAMIC_DRAW, DYNAMIC_READ e DYNAMIC_COPY
Buffer *buffer = gfx->getFactory()->createBuffer(size, usage);
pbge::Buffer::STATIC_DRAW);
void * mapped = buffer->map(pbge::Buffer::WRITE_ONLY);
// operar na região mapeada
buffer->unmap();
\end{verbatim}

\subsubsection {Shader}

Como explicado anteriormente, o OpenGL opera nas primitivas gráficas através de um pipeline, que tem cinco estágios principais: transformação de vértices, tesselagem, criação de novas primitivas, rasterização e operações por fragmento. Até a versão 1.5, esse pipeline tinha funcionalidade fixa. %Versao 1.5 de quem?

A partir da versão 2.0, os \texttt{shaders} foram introduzidos. Um shader é um programa que sobrescreve alguma das funcionalidades fixas do pipeline.

No OpenGL, \texttt{shader}s são criados através da função \texttt{glCreateShader}, que retorna o handler do shader criado. Após a criação do shader, o código fonte do programa a ser executado deve ser associado ao handler criado, isso é feito por \texttt{glShaderSource}, após a definição do código fonte do shader, ele é compilado por \texttt{glCompileShader}, após a compilação o shader está pronto para ser associado a um programa.

Na Pandora's Box, a implementação padrão do shader é dada pela classe GLShader:

\begin{verbatim}
// GLShader.h
#ifndef PBGE_GFX_OPENGL_GLSHADER_H
#define PBGE_GFX_OPENGL_GLSHADER_H
#include <string>

#include "pbge/gfx/Shader.h"

namespace pbge {
    class FileReader;
    class GraphicAPI;

    class GLShader : public Shader{
    public:
        GLShader() { 
            shaderID = 0;
            source = NULL;
            compiled = false;
        }

        static GLShader * loadSourceFromFile(FileReader * file, const ShaderType type);

        static GLShader * loadSource(const std::string & source, const ShaderType type);

        bool isCompiled() {
            return compiled;
        }

        bool compile(GraphicAPI * ogl);

        const std::string & getInfoLog() {
            return infoLog;
        }

        const ShaderType getType() {
            return type;
        }

        unsigned getID() { 
            return shaderID; 
        }

    private:

        void extractInfolog(GraphicAPI * ogl);

        std::string infoLog;

        GLuint shaderID;

        ShaderType type;

        char * source;

        bool compiled;
    };
}

#endif
\end{verbatim}
\begin{verbatim}
// GLShader.cpp
#include "OpenGLAPI/gfx/GLShader.h"
#include "pbge/core/File.h"

using namespace pbge;

GLShader * GLShader::loadSourceFromFile(FileReader * file, const ShaderType _type) {
    if(!file->is_open())
        return false;
    GLShader * shader = new GLShader;
    shader->type = _type;
    shader->source = new char[file->getSize() + 1];
    strcpy(shader->source, file->getData());
    file->close();
    return shader;
}

GLShader * GLShader::loadSource(const std::string & source, const ShaderType _type) {
    GLShader * shader = new GLShader;
    shader->type = _type;
    shader->source = new char[source.size() + 1];
    strcpy(shader->source, source.c_str());
    return shader;
}

bool GLShader::compile(GraphicAPI * gfx) {
    GLint status;
    if(shaderID == 0) { 
        if(type == VERTEX_SHADER)
            shaderID = glCreateShader(GL_VERTEX_SHADER);
        else if(type == FRAGMENT_SHADER)
            shaderID = glCreateShader(GL_FRAGMENT_SHADER);
        else 
            return false;
    }
    const GLchar * strPtr = const_cast<GLchar*>(source);
    glShaderSource(shaderID, 1, &strPtr, NULL);
    glCompileShader(shaderID);
    glGetShaderiv(shaderID, GL_COMPILE_STATUS, &status);
    compiled = (status == GL_TRUE);
    extractInfolog(gfx);
    return compiled;
}

void GLShader::extractInfolog(GraphicAPI * gfx) {
    GLint infoLogLength;
    GLchar * _infolog;
    glGetShaderiv(shaderID, GL_INFO_LOG_LENGTH, &infoLogLength);
    _infolog = new GLchar[infoLogLength];
    glGetShaderInfoLog(shaderID, infoLogLength, NULL, _infolog);
    this->infoLog = std::string(_infolog);
    delete [] _infolog;
}
\end{verbatim}
\subsubsection {GPUProgram}

No OpenGL, programas são grupos de shaders, nos quais cada fase do pipeline pode ser sobrescrita apenas uma vez, o que implica que os shaders que sobrescrevem um determinado passo do pipeline só podem especificar uma função main.

Na engine, esse mesmo conceito é implementado...

\subsubsection {Texture1D}

Texturas são tabelas de valores. 

\subsubsection {Texture2D}

\subsubsection {BufferTexture}

\subsubsection{VertexBuffer}
No início da computação gráfica, os vértices eram especificados um a um através de chamadas à API gráfica, por exemplo, a especificação de um triângulo no OpenGL era feita da seguinte maneira:

\begin{verbatim}
glBegin(GL_TRIANGLES);
glVertex3f(0.0f, 0.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glVertex3f(0.0f, 1.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glVertex3f(1.0f, 0.0f, 0.0f);
glNormal3f(0.0f, 0.0f, 1.0f);
glEnd();
\end{verbatim}

É possível observar que o número de chamadas de função cresce linearmente com a quantidade de vértices do modelo, além disso cada um dos atributos do vértice (posição, cor, normal, entre outros) era especificado através de uma chamada de função diferente.

\begin{wrapfigure}{r}{0.6\textwidth}
\vspace{-20pt}
\begin{center}
\includegraphics[width=0.6\textwidth]{vertexbuffer}
\end{center}
\vspace{-20pt}
\caption{O vertex buffer\label{vertexbuffer}}
\vspace{-10pt}
\end{wrapfigure}

Com o aumento da complexidade dos modelos, foi necessário reinventar a API existente, com isso foi criado o conceito de \texttt{vertex array}, que é simplesmente um vetor de valores de tipos variados em que cada atributo é especificado através de seu tipo primitivo (double, float, int, short, byte) número de componentes, significado (posição, vetor normal, coordenada de textura, \ldots) e a distância em bytes para o próximo valor desse atributo no vetor. Essa estrutura é exemplificada na figura ao lado.

Como a especificação desse modelo de dados era flexível e permitia enviar uma grande quantidade de dados para a \texttt{GPU} em um número constante de chamadas de função, ele foi rapidamente adotado pelos programadores.

Mas esse modelo não solucionava o problema de tráfego de dados entre a memória principal (RAM) e a memória de vídeo (VRAM). A solução foi colocar o \texttt{vertex array} dentro de um buffer gerenciado pela implementação da API gráfica, assim, a implementação poderia colocar dados muito utilizados dentro de regiões de fácil acesso, como a VRAM. Essa solução ficou conhecida como \texttt{Vertex Buffer}

Na Pandora's Box, \texttt{Vertex Buffers} são especificados através da classe VertexBuffer, sua estrutura interna é semelhante à apresentada na Figura~\ref{vertexbuffer}.
Cada vértice é específicado através da classe VertexAttrib que guarda informações sobre o primeiro índice do atributo dentro o buffer, seu significado, número de componentes e qual a distância entre valores consecutivos do atributo.

A forma recomendada de se criar um \texttt{VertexBuffer} é através do \texttt{VertexBufferBuilder}. % falar mais sobre o vertexbufferbuilder

% como construir com o builder: texto explicando?
\begin{verbatim}
pbge::VertexBuffer * criaVertexBuffer(pbge::GraphicAPI * gfx) {
    int nVertices = ...; // Inicializa com o número de vértices desejado
    pbge::VertexBufferBuilder builder(nVertices);
    pbge::VertexAttribBuilder vertex = builder.addAttrib(4, VertexAttrib::VERTEX);
    pbge::VertexAttribBuilder color = builder.addAttrib(4, VertexAttrib::COLOR);
    for(int i = 0; i < nVertices; i++) {
        float x, y, z, w; // Inicializados com os valores desejados
        float r, g, b, a; // Inicializados com os valores desejados
        builder.on(vertex).pushValue(x, y, z, w);
        builder.on(color).pushValue(r, g, b, a);
    }
    return builder.done(Buffer::STATIC_DRAW, gfx);
}
\end{verbatim}

% Esse código é suficiente?
% Talvez valha a pena comentar sobre o VBOModel...

\subsubsection {FrameBufferObject}

\subsection{Grafo de cena}
%TODO: Geral sobre o que é o grafo de cena, como é percorrido, etc.

\subsubsection{Tipos de nós}

\subsubsection{Node Visitors}

%TODO: O que é um visitor (referencia pro GOF só?)
Todos os \texttt{Visitors} padrão da engine herdam da classe abstrata \texttt{VisitorTrait}, que encapsula o algoritmo de busca em profundidade para grafos direcionados. 
Cada \texttt{visitor} é responsável por executar um determinado conjunto de métodos durante sua travessia no grafo de cena.

%checar os nomes dos visitors pq eu realmente não me lembro....
Os \texttt{visitors} definidos pela engine são: \texttt{UpdatePassVisitor} e \texttt{ColorPassVisitor}.

% O que é o UpdatePass do renderizador? Vai estar explicado antes?
% É executado o updatePass do nó?
O \texttt{UpdatePassVisitor} é responsável por fazer a travessia dentro do \texttt{UpdatePass} do renderizador. Durante a travessia esse visitor executa o método \texttt{updatePass} e em seguida continua a busca em profundidade e, por fim, executa o método \texttt{postUpdatePass}.

% Pensar melhor nesse nome
% Citar artigo da NVidia
Geometry instancing

\subsection{Renderizador}

O renderizador da engine gráfica utiliza um algoritmo de 3 fases:

\begin{itemize}
\item Atualização dos nós do grafo de cena
\item Processamento do grafo de cena
\item Pós-Processamento da imagem gerada pela fase de processamento
\end{itemize}

\subsubsection {Fase de atualização}
% Acho que essa explicação precisa acontecer antes da explicação sobre os NodeVisitors

Nessa fase cada nó do grafo de cena é atualizado através de uma chamada ao método updatePass da interface Node.

Para a implementação dessa fase foi utilizado o \texttt{Visitor}, % não esquecer de colocar referencia para o GOF aqui
que implementa uma busca em profundidade no grafo de cena. Essa é a única parte do algoritmo de renderização que não pode ser customizada.

\subsubsection {Fase de processamento do grafo de cena}

Nessa fase executa-se uma sequência de algoritmos definida pelo usuário da engine, a execução é equivalente ao código:

%verificar se os argumentos estão corretos
\begin{verbatim}
std::vector<SceneProcessor*>::iterator it;
for(it = processors.begin(); it != processors.end(); it++){
   if(it->isActive()){
       it->process(gfx, renderer);
   }
}
\end{verbatim}

Cada algoritmo deve implementar a interface \texttt{SceneProcessor}, que tem os seguintes métodos:

\begin{itemize}
\item \texttt{bool isInitialized(GraphicAPI*)}: método que indica se o algoritmo já preparou todas as suas dependências
\item \texttt{void initialize(GraphicAPI*, Renderer*)}: esse método deve criar todas as dependencias do método \texttt{process}
\item \texttt{void process(GraphicAPI*, Renderer*)}: executa o algoritmo de processamento
\item \texttt{bool isActive()}: indica se o algoritmo deve ou não ser executado
\end{itemize}

\subsubsection{Fase de pós-processamento}

%Em algum lugar vai ser explicado o que é o teste de profundidade do fragmento?
Essa fase é semelhante à anterior, porém o teste de profundidade do fragmento não é executado por padrão, a implementação do algoritmo deve ativá-lo manualmente.

A interface que deve ser implementada é a \texttt{ScenePostProcessor} que define métodos com a mesma semântica dos métodos do \texttt{SceneProcessor}.

\subsubsection{Algoritmos de processamento de cena pré-definidos}

A engine atualmente define apenas um algoritmo de processamento padrão, o \texttt{ColorPass}. % checar o nome do algoritmo

Esse algoritmo executa uma busca em profundidade no grafo de cena executando o método \texttt{colorPass} de cada nó. %Mudar se implementarmos o frustum culling

\subsubsection{Algoritmos de pós-processamento de cena pré-definidos}
 
Atualmente existem 2 algoritmos de pós-processamento implementados pelas classes: \texttt{FramebufferImageProcessor} e \texttt{BlitToFramebuffer}.

O \texttt{FramebufferImageProcessor} implementa uma técnica de renderização conhecida como ping-pong rendering. % achar o termo técnico correto
% descrever a técnica e a implementação.

O \texttt{BlitToFramebuffer} renderiza um retângulo com as dimensões da tela com a textura de nome \texttt{"color"} armazenada no renderizador.
% blit to framebuffer

\subsubsection{Algoritmos de pós-processamento customizados}

Foram desenvolvidos alguns algoritmos de pós-processamento customizados como exemplo. Eles estão disponíveis na aplicação de visualização de campos tensoriais. A implementação de cada algoritmo se resume a um fragment shader utilizado para instanciar um \texttt{FramebufferImageProcessor}. Esse fragment shader recebe a posição do fragmento e uma textura contendo a imagem a ser renderizada.

\begin{itemize}
\item \textbf{Inversor de cores:} O algoritmo de inversão de cores cria um vetor com os componentes \texttt{r,g,b}, calcula seu complemento e utiliza o resultado como a cor do fragmento:
\begin{verbatim}
pbge::FramebufferImageProcessor * colorInversor() {
    return new pbge::FramebufferImageProcessor(
        "uniform sampler2D color;\n"
        "varying vec2 position;\n"
        "void main() {\n"
        "   vec3 color = (texture2D(color, position.xy)).rgb;\n"
        "   color = 1 - color;\n"
        "   gl_FragColor = vec4(color, 1);\n"
        "}\n"
    );
}
\end{verbatim}
\item \textbf{Filtro de vermelho:} O filtro lê o componente veremelho da cor enviada pelo vertex shader e a utiliza no fragmento, sendo todos os outros componentes iguais a zero:
\begin{verbatim}
pbge::FramebufferImageProcessor * chooseRed() {
    return new pbge::FramebufferImageProcessor(
        "uniform sampler2D color;\n"
        "varying vec2 position;\n"
        "void main() {\n"
        "   float r = (texture2D(color, position.xy)).r;\n"
        "   gl_FragColor = vec4(r, 0, 0, 1);\n"
        "}\n"
    );
}
\end{verbatim}
\item \textbf{Lente senoidal:} A posição $(x_0, y_0)$ recebida é tal que $0 \leq x_0, y_0 \leq 1$. Ela é então mapeada para $(x_1, y_1)$, onde $-1 \leq x_0, y_0 \leq 1$. É calculado então o seno das componentes $x,y$ da posição multiplicadas por um fator que aumenta o efeito da lente. O resultado pertence ao intervalo $[-1,1]$, entretanto as coordenadas de textura estão no intervalo $[0,1]$. Por esse motivo o seno é multiplicado por $0.5$ e somado a $0.5$ resultando em um valor no mesmo intervalo das coordenadas de textura. Esse valor é utilizado para ler uma posição com um pequeno deslocamento da posição do fragmento atual, com isso é gerada uma leve deformação que simula o efeito de uma lente:
\begin{verbatim}
pbge::FramebufferImageProcessor * senoidalLens() {
    return new pbge::FramebufferImageProcessor(
        "varying vec2 position;\n"
        "uniform sampler2D color;\n"
        "void main(){\n"
        "   vec2 x = 2 * position - 1.0;\n"
        "   gl_FragColor = texture2D(color, 0.5 + 0.5 * sin(1.5 * x));\n"
        "}"
    );
}
\end{verbatim}
\end{itemize}

\subsection{Mecanismos da Engine}

\subsubsection{Passagem de parâmetros para o GPUProgram}

A customização do pipeline através de shaders gera grande flexibilidade, porém essa customização só é interessante devido a possibilidade de passagem de diferentes parâmetros para o shader.

Um programa do OpenGL pode receber dois tipos de parâmetros:

\begin{itemize}
\item Uniformes: um valor que é constante para uma dada primitiva, por exemplo, para um triângulo, o processamento de seus três vértices utilizam o mesmo valor de uniforme.
\item Atributos: um valor que é constante para um vértice. Atributos só podem ser acessados dentro do \texttt{vertex shader}. No exemplo acima, cada um dos vértices do triângulo poderia ter um valor diferente para o atributo.
\end{itemize}

No OpenGL, as uniformes são enviadas de forma homogênea através da seguinte rotina:

\begin{verbatim}
// troca o programa associado ao contexto de renderização
glUseProgram(programID);
// localização da uniforme dentro do programa
GLint location = glGetUniformLocation(programID, nome_da_uniforme);
// Existe uma função da família glUniform* para cada tipo de atributo.
// Além disso, para o caso de vetores de valores, existem as funções 
// cujo nome tem o sufixo v, por exemplo, glUniform1fv
// no caso de um float:
glUniform1f(location, valor);
\end{verbatim}

Para atributos, o processo é semelhante:

\begin{verbatim}
glUseProgram(programID);
// localização do atributo dentro do programa
GLint location = glGetAttribLocation(programID, nome_do_atributo);
// Existe uma função da família glVertexAttrib* para cada tipo de atributo.
// Além disso, para o caso de vetores de valores, existem as funções 
// cujo nome tem o sufixo v, por exemplo, glVertexAttrib1fv
// no caso de um float:
glVertexAttrib1f(location, valor);
\end{verbatim}

Dentro da Pandora's Box, o mecanismo de passagem de parâmetros para o shader é implementado através do \texttt{UniformSet}, \texttt{UniformStack}, \texttt{GPUProgram}, \texttt{UniformValue}, \texttt{AttribBinder} e \texttt{BuiltInUniformBinder}.

Como foi citado anteriormente, a última etapa da atualização de estados é a sincronização dos parâmetros do shader. Nessa fase, inicialmente, cada um dos \texttt{UniformInfo} gerados durante a compilação do shader é utilizado para buscar um \texttt{UniformValue} dentro da \texttt{UniformStack}, o uniform value encontrado é então associado ao programa através do mecanismo ilustrado no código abaixo para o caso do GPUProgram implementado para OpenGL:

\begin{verbatim}
void GLProgram::updateUniforms(GraphicAPI * gfx) {
    std::vector<UniformBindAndInfo>::iterator it;
    for(it = uniforms.begin(); it != uniforms.end(); it++) {
        UniformValue * value = gfx->searchUniform(it->getInfo());
        if(it->shouldUpdate(value)) {
            it->update(value);
            value->bindValueOn(this, it->getInfo(), gfx);
        }
    }
    

// cada um dos tipos de UniformValue tem um método de associação
// específico no GPUProgram
// Para o caso do UniformFloat:
void UniformFloat::bindValueOn(GPUProgram *p, const UniformInfo & info, GraphicAPI *ogl) {
    float * values = static_cast<float *>(getValueAt(0));
    p->bindFloat(info, ogl, values, std::min(getNumberOfElements(), info.getNumberOfElements()));
}
\end{verbatim}

Após essa etapa de associação de valores, os valores uniformes \texttt{built-in} são enviados ao shader. O envio de \texttt{built-in}s é feito através dos \texttt{BuiltInUniformBinder}, que são classes especializadas para cada um dos tipos de valor built-in (atualmente apenas as matrizes gl\_ProjectionMatrix, gl\_ModelViewMatrix, gl\_ModelViewProjectionMatrix, pbge\_ProjectionMatrix, pbge\_ViewMatrix, pbge\_ModelViewMatrix, pbge\_ModelViewProjectionMatrix têm um \texttt{BuiltInUniformBinder} associado).

Os \texttt{BuiltInUniformBinder} implementados na Pandora's Box são de dois tipos:

\begin{itemize}

\item \texttt{binder} de variável obsoleta: são classes que enviam para o shader uniformes que foram extintas por versões novas do OpenGL (gl\_ProjectionMatrix, gl\_ModelViewMatrix e gl\_ModelViewProjectionMatrix). Esses \texttt{binder}s utilizam-se das funções obsoletas \texttt{glMatrixMode} e \texttt{glLoadMatrix} para enviar valores ao shader. Por exemplo, no caso da DeprModelViewProjectionBinder que envia o valor da matriz gl\_ModelViewProjection:
\begin{verbatim}
void DeprModelViewProjectionBinder::bind(pbge::GraphicAPI *gfx) {
    math3d::matrix44 projection = gfx->getProjectionMatrix()->get().transpose();
    math3d::matrix44 modelView = (gfx->getViewMatrix()->get() * gfx->getModelMatrix()->get()).transpose();
    glMatrixMode(GL_MODELVIEW);
    glLoadMatrixf(modelView);
    glMatrixMode(GL_PROJECTION);
    glLoadMatrixf(projection);
}
\end{verbatim}

\item \texttt{binder} de \texttt{built-in} da Pandora's Box: são classes que enviam para o shader variáveis que tem significado especial para a engine desenvolvida (pbge\_ProjectionMatrix, pbge\_ViewMatrix, pbge\_ModelViewMatrix e pbge\_ModelViewProjectionMatrix). Esses binders utilizam-se da função glUniformMatrix4fv, que tem a mesma funcionalidade glUniform1f, porém para matrizes. Os \texttt{binder}s dessa categoria são implementados pelo template texttt{MatrixBinder}:
\begin{verbatim}
template<typename MatrixGetter>
class MatrixBinder : public BuiltInUniformBinder {
public:
    MatrixBinder(GLint _location) : location(_location) {}

    void bind(GraphicAPI * gfx) {
        if(getter.shouldChange(gfx)) {
            math3d::matrix44 m = getter(gfx);
            glUniformMatrix4fv(location, 1, GL_TRUE, m);
        }
    }
private:
    MatrixGetter getter;
    
    GLint location;
};
\end{verbatim}
Esse template envia uma matriz para a uniforme localizada identificada por \_location e utiliza-se de um MatrixGetter para conseguir o valor que deve ser enviado. Por exemplo, para o caso do pbge\_ModelViewProjectionMatrix, temos o \texttt{MatrixGetter}:
\begin{verbatim}
class ModelViewProjectionMatrixGetter {
public:
    const math3d::matrix44 operator() (GraphicAPI* gfx) {
        viewStamp = gfx->getViewMatrix()->getStamp();
        modelStamp = gfx->getModelMatrix()->getStamp();
        projStamp = gfx->getProjectionMatrix()->getStamp();
        math3d::matrix44 view = gfx->getViewMatrix()->get();
        math3d::matrix44 model = gfx->getModelMatrix()->get();
        math3d::matrix44 projection = gfx->getProjectionMatrix()->get();
        return projection * view * model;
    }
    bool shouldChange(GraphicAPI * gfx) {
        return viewStamp != gfx->getViewMatrix()->getStamp() ||
               modelStamp != gfx->getModelMatrix()->getStamp() ||
               projStamp != gfx->getProjectionMatrix()->getStamp();
    }
private:
    unsigned long viewStamp, modelStamp, projStamp;
};
\end{verbatim}
\end{itemize}

O mecanismo para o envio dos atributos é semelhante ao utilizada para enviar as uniformes \texttt{built-in}. Cada um dos tipos de atributo definidos na \texttt{enum} \texttt{pbge::VertexAttrib::Type} tem uma classe (\texttt{AttrBinder}) especializada em associar o atributo ao shader.

Os \texttt{AttrBinder}s pertencem à uma das três categorias abaixo:

\begin{itemize}

\item binder de atributo obsoleto: Atributos obsoletos são aqueles que existiam na linguagem de shader GLSL mas que foram removidos em versões mais recentes. A Pandora's Box oferece suporte aos seguintes atributos obsoletos: gl\_Vertex, gl\_Normal, gl\_Color e gl\_SecondaryColor.

No caso do atributo gl\_Vertex, temos o seguinte binder:

\begin{verbatim}
class DeprVertexBinder : public AttrBinder {
public:
    void bind(VertexBuffer * attrs) {
        VertexAttrib * attr = attrs->findByType(VertexAttrib::VERTEX);
        glEnableClientState(GL_VERTEX_ARRAY);
        glVertexPointer(attr->getNCoord(), GL_FLOAT, attr->getStride(), ATTRIB_POINTER_OFFSET(attr->getOffset()));
    }

    void unbind() {
        glDisableClientState(GL_VERTEX_ARRAY);
    }
};
\end{verbatim}

\item binder de atributo definido pela engine: A Pandora's Box define os seguintes atributos: pbge\_Vertex, pbge\_Normal, pbge\_Color e pbge\_SecondaryColor, sendo que todos esses atributos enviados para o shader através da classe \texttt{SemanticAttribBinder}:

\begin{verbatim}
class SemanticAttribBinder : public AttrBinder {
public:
    SemanticAttribBinder(const VertexAttrib::Type attrType, GLint attrLocation): type(attrType), location(attrLocation){}

    void bind(VertexBuffer * attrs) {
        VertexAttrib * attr = attrs->findByType(type);
        glVertexAttribPointer(location, attr->getNCoord(), GL_FLOAT, GL_FALSE, attr->getStride(), ATTRIB_POINTER_OFFSET(attr->getOffset()));
        glEnableVertexAttribArray(location);
    }

    void unbind() {
        glDisableVertexAttribArray(location);
    }
private:
    VertexAttrib::Type type;
    GLint location;
};
\end{verbatim}

\item binder de atributo definido pelo usuário da engine: Esses atributos são mapeados para o shader através do \texttt{CustomAttrBinder}:

\begin{verbatim}
class CustomAttrBinder : public AttrBinder {
public:
    CustomAttrBinder(std::string attrName, GLint attrLocation) : name(attrName), location(attrLocation) {}

    void bind(VertexBuffer * attrs) {
        VertexAttrib * attr = attrs->findByName(name);
        glVertexAttribPointer(location, attr->getNCoord(), GL_FLOAT, GL_FALSE, attr->getStride(), ATTRIB_POINTER_OFFSET(attr->getOffset()));
        glEnableVertexAttribArray(location);
    }

    void unbind() {
        glDisableVertexAttribArray(location);
    }
private:
    std::string name;
    GLint location;
};
\end{verbatim}

\end{itemize}

% TODO: mover o mapeamento para antes dos parâmetros do shader
\subsubsection{Mapeamento e gerenciamento dos estados}

Em placas de vídeo modernas, dispositivos altamente paralelos, as trocas de estado podem fazer com que o pipeline gráfico tenha que ser esvaziado, o que pode causar um grande impacto no desempenho da aplicação, por isso, é necessário evitar trocas de estado redundantes, minimizar trocas de estado e agrupar as trocas de estado.

Na Pandora's Box, esse trabalho é delegado à classe \texttt{StateSet} e à algumas classes controladoras menores. A \texttt{StateSet} é uma classe que controla os objetos que estão associados ao contexto gráfico.

\subsubsection{Desenho de modelos}

Para lidar com a variedade de tipos de modelos e com as diferentes técnicas de renderização, foi desenvolvido um controlador de desenho.

A implementação dessa classe utilizando OpenGL 
% introdução ao drawcontroller
%explicar a implementação para um model generico
% explicar a implementação para VBOModel
% explicar a implementação do render instanced

\subsection{Visualização de campos tensoriais}

A aplicação de visualização de campos tensoriais é dividida em duas etapas:

\begin{itemize}
\item Compilação do formato Analyze\textregistered  para o formato \texttt{.ctf} (Compiled Tensor Field)
\item Apresentação do campo contido no arquivo \texttt{.ctg}
\end{itemize}

\subsubsection{O formato Analyze\textregistered}

O formato Analyze\textregistered\space é um formato de armazenamento de informações de imagens de ressonância magnética. A informação é dividida em dois arquivos: um cabeçalho (extensão \texttt{.hdr}) com informações sobre o campo (dimensões, ordenação, identificação e histórico) e o arquivo de imagem (extensão \texttt{.img}) contendo somente os valores da imagem (organizados conforme a descrição do cabeçalho).

Para o desenvolvimento do leitor de arquivos Analyze\textregistered\space foi feita a suposição de que os nomes dos arquivos (\texttt{.hdr} e \texttt{.img}) são iguais visando simplificar a utilização e implementação.

\subsubsection{O formato Compiled Tensor Field (.ctf)}

O formato Compiled Tensor Field (\texttt{.ctf}) foi desenvolvido para armazenamento de informações sobre o campo tensorial a ser mostrado na aplicação de visualização de campos tensoriais. É um formato binário que contém o número de elipsóides (representação visual do tensor) no arquivo seguido por um conjunto de matrizes de transformação linear. Cada matriz será aplicada a uma esfera para obter um elipsóide na posição correta no campo. Por esse motivo ela contém uma escala (proporcional aos autovalores do tensor aplicados nos eixos cartesianos), uma rotação (dos eixos cartesianos para os eixos definidos pelos autovetores do tensor) e uma translação (para posicionar o elipsóide corretamente no campo).

\subsubsection{Compilação da imagem de ressonância magnética}

Na etapa de compilação a imagem de ressonância magnética é lida e os tensores armazenados em um vetor. Dada a seguinte definição para um tensor $A$ $3 \times 3$ nulo (para um dado $\varepsilon > 0$) para $1 \leq i, j \leq 3$, $i, j \in \mathbb{I}$:

\begin{math}
|A_{i,j}| < \varepsilon
\end{math}

Todos os tensores nulos são ignorados na compilação. São então calculados os autovalores e autovetores de todos os tensores não nulos, geradas as matrizes de transformação linear que levam uma esfera centralizada na origem para um elipsóide na posição correta no campo e armazenadas em um vetor. 

Como tais matrizes são matrizes de transformação homogênea, sabemos que a última linha sempre será $(0,0,0,1)$. Assim é possível ocultar tais dados e enviar outras informações em seu lugar (é necessário substituir os valores dessa linha para realizar quaisquer operações com a matriz). Nessa linha são armazenados os valores das equações (\ref{af}), (\ref{linearCase}), (\ref{planarCase}) e (\ref{sphericalCase}) (definidas na página \pageref{af}) que serão utilizados como diferentes políticas de escolha de nível de transparência (alfa) e cor dos elipsóides.

As matrizes são então reorganizadas em blocos de proximidade para otimizar a utilização pela aplicação de visualização. O vetor de matrizes reordenado é finalmente escrito no arquivo, além das informações iniciais sobre o campo.

\subsubsection{Apresentação do campo compilado}

O arquivo \texttt{.ctf} é lido e cada bloco de matrizes é enviado como \texttt{uniform} para o \texttt{shader} que as aplica a esferas. A política de transparência (alfa) dos elipsóides é escolhida pelo usuário, sendo o valor de alfa algum dos quatro resultados das equações de anisotropia fracionada. A cor aplicada a cada elipsóide é calculada a partir do valor de alfa em uma rampa de cores também definida pelo usuário.

Para a translação e rotação do campo foram implementados um \texttt{KeyboardEventHandler} e um \texttt{MouseEventHandler} respectivamente que atualizam os nós de transformação.

\subsection{Técnicas aplicadas}

\subsubsection{Depth Peeling}
No campo tensorial em diversos casos existem elipsóides sobrepostos. Para observar alguns tipos de estrutura é interessante que tais elipsóides possuam algum nível de transparência. Para isso é necessário simular a transparência através de combinações de cores sobrepostas. Existem técnicas~\cite{alphasorting} que dependem dos objetos serem renderizados dos mais distantes para os mais próximos da câmera, entretanto no caso do campo esse tipo de processo se torna muito lento devido à grande quantidade de objetos a serem ordenados antes de cada renderização. Por esse motivo é necessário algum algoritmo independente da ordem de renderização.

Depth peeling~\cite{everitt} é uma técnica iterativa que consiste de remoções de camadas próximas a cada iteração. Inicialmente a cena é renderizada normalmente armazenando o color buffer e o depth buffer em buffers auxiliares. A cada nova iteração todos os fragmentos com profundidade menor ou igual à profundidade armazenada no depth buffer auxiliar são descartados. Um novo depth buffer auxiliar é gerado a partir das profundidades dos fragmentos restantes, que são então renderizados e o resultado (color buffer) é acumulado no color buffer auxiliar.

Para a realização da técnica completa são necessárias $N$ iterações, onde $N$ é o número máximo de fragmentos sobrepostos na cena. Entretanto foi fixado um número de iterações para diminuir a complexidade da técnica.

Na aplicação de exemplo o depth peeling foi implementado como um processador de cena sendo que a cada iteração o grafo de cena é percorrido uma vez.

As imagens abaixo exemplificam essa técnica com duas esferas acompanhadas do resultado da iteração.

\begin{wrapfigure}{l}{\textwidth}
\vspace{-20pt}
\begin{center}
\subfigure[Primeira iteração]{\includegraphics[width=0.49\textwidth]{depthpeeling1}}
\subfigure[Segunda iteração]{\includegraphics[width=0.49\textwidth]{depthpeeling2}}
\subfigure[Terceira iteração]{\includegraphics[width=0.49\textwidth]{depthpeeling3}}
\end{center}
\vspace{-20pt}
\caption{Campo de grama}
\vspace{-10pt}
\end{wrapfigure}
